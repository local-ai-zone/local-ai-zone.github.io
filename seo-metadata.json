{
  "site": {
    "title": "GGUF Model Discovery - Browse & Download AI Models",
    "description": "Discover and download GGUF format machine learning models. Browse thousands of quantized AI models with detailed information, download counts, and direct links.",
    "keywords": "GGUF models, machine learning, AI models, quantized models, model download, Hugging Face, LLaMA, neural networks, deep learning, Qwen models, Gemma models, Llama models, Mistral models, DeepSeek models, BERT models, Phi models, Q4_0 quantization, Q4_K_M quantization, Q5_K_M quantization, Q8_0 quantization, F16 quantization",
    "structuredData": {
      "@context": "https://schema.org",
      "@type": "WebSite",
      "name": "GGUF Model Discovery",
      "description": "Browse and download GGUF format machine learning models",
      "url": "https://local-ai-zone.github.io",
      "potentialAction": {
        "@type": "SearchAction",
        "target": {
          "@type": "EntryPoint",
          "urlTemplate": "https://local-ai-zone.github.io/#search={search_term_string}"
        },
        "query-input": "required name=search_term_string"
      },
      "mainEntity": {
        "@type": "DataCatalog",
        "name": "GGUF Model Catalog",
        "description": "Comprehensive catalog of GGUF format machine learning models",
        "numberOfItems": 2066,
        "keywords": "Qwen, Gemma, Llama, Mistral, DeepSeek, BERT, Phi"
      }
    }
  },
  "models": {
    "glm-4-5-air": {
      "title": "Glm 4.5 Air - BF16 GGUF Model",
      "description": "Download Glm 4.5 Air in BF16 quantization format. File size: 46.4 GB. 15,083 downloads. 31 likes. Direct download from Hugging Face.",
      "keywords": "Glm 4.5 Air, BF16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Glm 4.5 Air",
        "description": "Download Glm 4.5 Air in BF16 quantization format. File size: 46.4 GB. 15,083 downloads. 31 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "46.4 GB",
        "downloadUrl": "https://huggingface.co/unsloth/GLM-4.5-Air-GGUF/resolve/main/BF16/GLM-4.5-Air-BF16-00001-of-00005.gguf",
        "url": "https://huggingface.co/unsloth/GLM-4.5-Air-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 31
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 15083
        }
      },
      "openGraph": {
        "title": "Glm 4.5 Air - GGUF Model Download",
        "description": "Download Glm 4.5 Air in BF16 quantization format. File size: 46.4 GB. 15,083 downloads. 31 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=glm-4-5-air",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Glm 4.5 Air GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=glm-4-5-air"
    },
    "qwen-image": {
      "title": "Qwen Image - Q2_K GGUF Model",
      "description": "Download Qwen Image in Q2_K quantization format. Qwen model File size: 6.6 GB. 506 downloads. 7 likes. Direct download from Hugging Face.",
      "keywords": "Qwen Image, Q2_K, GGUF model, download, Qwen, Qwen model, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Qwen Image",
        "description": "Download Qwen Image in Q2_K quantization format. Qwen model File size: 6.6 GB. 506 downloads. 7 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.6 GB",
        "downloadUrl": "https://huggingface.co/QuantStack/Qwen-Image-GGUF/resolve/main/Qwen_Image-Q2_K.gguf",
        "url": "https://huggingface.co/QuantStack/Qwen-Image-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 7
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 506
        }
      },
      "openGraph": {
        "title": "Qwen Image - GGUF Model Download",
        "description": "Download Qwen Image in Q2_K quantization format. Qwen model File size: 6.6 GB. 506 downloads. 7 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=qwen-image",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Qwen Image GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=qwen-image"
    },
    "gpt-oss-20b": {
      "title": "Gpt Oss 20b - F16 GGUF Model",
      "description": "Download Gpt Oss 20b in F16 quantization format. File size: 12.8 GB. 855 downloads. 3 likes. Direct download from Hugging Face.",
      "keywords": "Gpt Oss 20b, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Gpt Oss 20b",
        "description": "Download Gpt Oss 20b in F16 quantization format. File size: 12.8 GB. 855 downloads. 3 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "12.8 GB",
        "downloadUrl": "https://huggingface.co/gabriellarson/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20B-F16.gguf",
        "url": "https://huggingface.co/gabriellarson/gpt-oss-20b-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 3
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 855
        }
      },
      "openGraph": {
        "title": "Gpt Oss 20b - GGUF Model Download",
        "description": "Download Gpt Oss 20b in F16 quantization format. File size: 12.8 GB. 855 downloads. 3 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=gpt-oss-20b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Gpt Oss 20b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=gpt-oss-20b"
    },
    "thedrummer-cydonia-r1-24b-v4": {
      "title": "Thedrummer Cydonia R1 24b V4 - BF16 GGUF Model",
      "description": "Download Thedrummer Cydonia R1 24b V4 in BF16 quantization format. File size: 43.9 GB. 3,511 downloads. Direct download from Hugging Face.",
      "keywords": "Thedrummer Cydonia R1 24b V4, BF16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Thedrummer Cydonia R1 24b V4",
        "description": "Download Thedrummer Cydonia R1 24b V4 in BF16 quantization format. File size: 43.9 GB. 3,511 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "43.9 GB",
        "downloadUrl": "https://huggingface.co/bartowski/TheDrummer_Cydonia-R1-24B-v4-GGUF/resolve/main/TheDrummer_Cydonia-R1-24B-v4-bf16.gguf",
        "url": "https://huggingface.co/bartowski/TheDrummer_Cydonia-R1-24B-v4-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 3511
        }
      },
      "openGraph": {
        "title": "Thedrummer Cydonia R1 24b V4 - GGUF Model Download",
        "description": "Download Thedrummer Cydonia R1 24b V4 in BF16 quantization format. File size: 43.9 GB. 3,511 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=thedrummer-cydonia-r1-24b-v4",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Thedrummer Cydonia R1 24b V4 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=thedrummer-cydonia-r1-24b-v4"
    },
    "xbai-o4": {
      "title": "Xbai O4 - Q2_K GGUF Model",
      "description": "Download Xbai O4 in Q2_K quantization format. File size: 11.5 GB. 2,933 downloads. 14 likes. Direct download from Hugging Face.",
      "keywords": "Xbai O4, Q2_K, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Xbai O4",
        "description": "Download Xbai O4 in Q2_K quantization format. File size: 11.5 GB. 2,933 downloads. 14 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "11.5 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/XBai-o4-GGUF/resolve/main/XBai-o4.Q2_K.gguf",
        "url": "https://huggingface.co/mradermacher/XBai-o4-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 14
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 2933
        }
      },
      "openGraph": {
        "title": "Xbai O4 - GGUF Model Download",
        "description": "Download Xbai O4 in Q2_K quantization format. File size: 11.5 GB. 2,933 downloads. 14 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=xbai-o4",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Xbai O4 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=xbai-o4"
    },
    "zai-org-glm-4-5-air": {
      "title": "Zai Org.glm 4.5 Air - F16 GGUF Model",
      "description": "Download Zai Org.glm 4.5 Air in F16 quantization format. File size: 13.0 GB. 2,249 downloads. 3 likes. Direct download from Hugging Face.",
      "keywords": "Zai Org.glm 4.5 Air, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Zai Org.glm 4.5 Air",
        "description": "Download Zai Org.glm 4.5 Air in F16 quantization format. File size: 13.0 GB. 2,249 downloads. 3 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "13.0 GB",
        "downloadUrl": "https://huggingface.co/DevQuasar/zai-org.GLM-4.5-Air-GGUF/resolve/main/zai-org.GLM-4.5-Air.f16-00009-of-00017.gguf",
        "url": "https://huggingface.co/DevQuasar/zai-org.GLM-4.5-Air-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 3
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 2249
        }
      },
      "openGraph": {
        "title": "Zai Org.glm 4.5 Air - GGUF Model Download",
        "description": "Download Zai Org.glm 4.5 Air in F16 quantization format. File size: 13.0 GB. 2,249 downloads. 3 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=zai-org-glm-4-5-air",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Zai Org.glm 4.5 Air GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=zai-org-glm-4-5-air"
    },
    "xbai-o4-i1": {
      "title": "Xbai O4 I1 - IQ1_S GGUF Model",
      "description": "Download Xbai O4 I1 in IQ1_S quantization format. File size: 6.8 GB. 1,497 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Xbai O4 I1, IQ1_S, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Xbai O4 I1",
        "description": "Download Xbai O4 I1 in IQ1_S quantization format. File size: 6.8 GB. 1,497 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/XBai-o4-i1-GGUF/resolve/main/XBai-o4.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/XBai-o4-i1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 1497
        }
      },
      "openGraph": {
        "title": "Xbai O4 I1 - GGUF Model Download",
        "description": "Download Xbai O4 I1 in IQ1_S quantization format. File size: 6.8 GB. 1,497 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=xbai-o4-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Xbai O4 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=xbai-o4-i1"
    },
    "skywork-mindlink-32b-0801": {
      "title": "Skywork Mindlink 32b 0801 - BF16 GGUF Model",
      "description": "Download Skywork Mindlink 32b 0801 in BF16 quantization format. File size: 37.1 GB. 1,313 downloads. 2 likes. Direct download from Hugging Face.",
      "keywords": "Skywork Mindlink 32b 0801, BF16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Skywork Mindlink 32b 0801",
        "description": "Download Skywork Mindlink 32b 0801 in BF16 quantization format. File size: 37.1 GB. 1,313 downloads. 2 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "37.1 GB",
        "downloadUrl": "https://huggingface.co/bartowski/Skywork_MindLink-32B-0801-GGUF/resolve/main/Skywork_MindLink-32B-0801-bf16/Skywork_MindLink-32B-0801-bf16-00001-of-00002.gguf",
        "url": "https://huggingface.co/bartowski/Skywork_MindLink-32B-0801-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 2
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 1313
        }
      },
      "openGraph": {
        "title": "Skywork Mindlink 32b 0801 - GGUF Model Download",
        "description": "Download Skywork Mindlink 32b 0801 in BF16 quantization format. File size: 37.1 GB. 1,313 downloads. 2 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=skywork-mindlink-32b-0801",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Skywork Mindlink 32b 0801 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=skywork-mindlink-32b-0801"
    },
    "glm-4-5": {
      "title": "Glm 4.5 - BF16 GGUF Model",
      "description": "Download Glm 4.5 in BF16 quantization format. File size: 46.5 GB. 1,239 downloads. 10 likes. Direct download from Hugging Face.",
      "keywords": "Glm 4.5, BF16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Glm 4.5",
        "description": "Download Glm 4.5 in BF16 quantization format. File size: 46.5 GB. 1,239 downloads. 10 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "46.5 GB",
        "downloadUrl": "https://huggingface.co/unsloth/GLM-4.5-GGUF/resolve/main/BF16/GLM-4.5-BF16-00005-of-00015.gguf",
        "url": "https://huggingface.co/unsloth/GLM-4.5-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 10
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 1239
        }
      },
      "openGraph": {
        "title": "Glm 4.5 - GGUF Model Download",
        "description": "Download Glm 4.5 in BF16 quantization format. File size: 46.5 GB. 1,239 downloads. 10 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=glm-4-5",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Glm 4.5 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=glm-4-5"
    },
    "huihui-qwen3-30b-a3b-thinking-2507-abliterated": {
      "title": "Huihui Qwen3 30b A3b Thinking 2507 Abliterated - Q2_K GGUF Model",
      "description": "Download Huihui Qwen3 30b A3b Thinking 2507 Abliterated in Q2_K quantization format. File size: 10.5 GB. 1,202 downloads. 4 likes. Direct download from Hugging Face.",
      "keywords": "Huihui Qwen3 30b A3b Thinking 2507 Abliterated, Q2_K, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Huihui Qwen3 30b A3b Thinking 2507 Abliterated",
        "description": "Download Huihui Qwen3 30b A3b Thinking 2507 Abliterated in Q2_K quantization format. File size: 10.5 GB. 1,202 downloads. 4 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "10.5 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Huihui-Qwen3-30B-A3B-Thinking-2507-abliterated-GGUF/resolve/main/Huihui-Qwen3-30B-A3B-Thinking-2507-abliterated.Q2_K.gguf",
        "url": "https://huggingface.co/mradermacher/Huihui-Qwen3-30B-A3B-Thinking-2507-abliterated-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 4
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 1202
        }
      },
      "openGraph": {
        "title": "Huihui Qwen3 30b A3b Thinking 2507 Abliterated - GGUF Model Download",
        "description": "Download Huihui Qwen3 30b A3b Thinking 2507 Abliterated in Q2_K quantization format. File size: 10.5 GB. 1,202 downloads. 4 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=huihui-qwen3-30b-a3b-thinking-2507-abliterated",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Huihui Qwen3 30b A3b Thinking 2507 Abliterated GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=huihui-qwen3-30b-a3b-thinking-2507-abliterated"
    },
    "zai-org-glm-4-5": {
      "title": "Zai Org.glm 4.5 - Q3_K_M GGUF Model",
      "description": "Download Zai Org.glm 4.5 in Q3_K_M quantization format. File size: 12.9 GB. 1,159 downloads. 2 likes. Direct download from Hugging Face.",
      "keywords": "Zai Org.glm 4.5, Q3_K_M, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Zai Org.glm 4.5",
        "description": "Download Zai Org.glm 4.5 in Q3_K_M quantization format. File size: 12.9 GB. 1,159 downloads. 2 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "12.9 GB",
        "downloadUrl": "https://huggingface.co/DevQuasar/zai-org.GLM-4.5-GGUF/resolve/main/zai-org.GLM-4.5.Q3_K_M-00004-of-00013.gguf",
        "url": "https://huggingface.co/DevQuasar/zai-org.GLM-4.5-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 2
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 1159
        }
      },
      "openGraph": {
        "title": "Zai Org.glm 4.5 - GGUF Model Download",
        "description": "Download Zai Org.glm 4.5 in Q3_K_M quantization format. File size: 12.9 GB. 1,159 downloads. 2 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=zai-org-glm-4-5",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Zai Org.glm 4.5 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=zai-org-glm-4-5"
    },
    "mindlink-32b-0801": {
      "title": "Mindlink 32b 0801 - F16 GGUF Model",
      "description": "Download Mindlink 32b 0801 in F16 quantization format. File size: 61.0 GB. 1,088 downloads. 4 likes. Direct download from Hugging Face.",
      "keywords": "Mindlink 32b 0801, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Mindlink 32b 0801",
        "description": "Download Mindlink 32b 0801 in F16 quantization format. File size: 61.0 GB. 1,088 downloads. 4 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "61.0 GB",
        "downloadUrl": "https://huggingface.co/gabriellarson/MindLink-32B-0801-GGUF/resolve/main/MindLink-32B-0801-F16.gguf",
        "url": "https://huggingface.co/gabriellarson/MindLink-32B-0801-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 4
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 1088
        }
      },
      "openGraph": {
        "title": "Mindlink 32b 0801 - GGUF Model Download",
        "description": "Download Mindlink 32b 0801 in F16 quantization format. File size: 61.0 GB. 1,088 downloads. 4 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=mindlink-32b-0801",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Mindlink 32b 0801 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=mindlink-32b-0801"
    },
    "cydonia-r1-24b-v4-i1": {
      "title": "Cydonia R1 24b V4 I1 - IQ1_S GGUF Model",
      "description": "Download Cydonia R1 24b V4 I1 in IQ1_S quantization format. File size: 4.9 GB. 1,040 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Cydonia R1 24b V4 I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Cydonia R1 24b V4 I1",
        "description": "Download Cydonia R1 24b V4 I1 in IQ1_S quantization format. File size: 4.9 GB. 1,040 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "4.9 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Cydonia-R1-24B-v4-i1-GGUF/resolve/main/Cydonia-R1-24B-v4.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/Cydonia-R1-24B-v4-i1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 1040
        }
      },
      "openGraph": {
        "title": "Cydonia R1 24b V4 I1 - GGUF Model Download",
        "description": "Download Cydonia R1 24b V4 I1 in IQ1_S quantization format. File size: 4.9 GB. 1,040 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=cydonia-r1-24b-v4-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Cydonia R1 24b V4 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=cydonia-r1-24b-v4-i1"
    },
    "zerofata-ms3-2-paintedfantasy-visage-v2-33b": {
      "title": "Zerofata Ms3.2 Paintedfantasy Visage V2 33b - BF16 GGUF Model",
      "description": "Download Zerofata Ms3.2 Paintedfantasy Visage V2 33b in BF16 quantization format. File size: 37.0 GB. 1,013 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Zerofata Ms3.2 Paintedfantasy Visage V2 33b, BF16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Zerofata Ms3.2 Paintedfantasy Visage V2 33b",
        "description": "Download Zerofata Ms3.2 Paintedfantasy Visage V2 33b in BF16 quantization format. File size: 37.0 GB. 1,013 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "37.0 GB",
        "downloadUrl": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-Visage-v2-33B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-Visage-v2-33B-bf16/zerofata_MS3.2-PaintedFantasy-Visage-v2-33B-bf16-00001-of-00002.gguf",
        "url": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-Visage-v2-33B-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 1013
        }
      },
      "openGraph": {
        "title": "Zerofata Ms3.2 Paintedfantasy Visage V2 33b - GGUF Model Download",
        "description": "Download Zerofata Ms3.2 Paintedfantasy Visage V2 33b in BF16 quantization format. File size: 37.0 GB. 1,013 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=zerofata-ms3-2-paintedfantasy-visage-v2-33b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Zerofata Ms3.2 Paintedfantasy Visage V2 33b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=zerofata-ms3-2-paintedfantasy-visage-v2-33b"
    },
    "gpt-oss-120b": {
      "title": "Gpt Oss 120b - Unknown GGUF Model",
      "description": "Download Gpt Oss 120b in Unknown quantization format. File size: 29.6 GB. 999 downloads. 12 likes. Direct download from Hugging Face.",
      "keywords": "Gpt Oss 120b, Unknown, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Gpt Oss 120b",
        "description": "Download Gpt Oss 120b in Unknown quantization format. File size: 29.6 GB. 999 downloads. 12 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "29.6 GB",
        "downloadUrl": "https://huggingface.co/ggml-org/gpt-oss-120b-GGUF/resolve/main/gpt-oss-120b-mxfp4-00002-of-00003.gguf",
        "url": "https://huggingface.co/ggml-org/gpt-oss-120b-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 12
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 999
        }
      },
      "openGraph": {
        "title": "Gpt Oss 120b - GGUF Model Download",
        "description": "Download Gpt Oss 120b in Unknown quantization format. File size: 29.6 GB. 999 downloads. 12 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=gpt-oss-120b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Gpt Oss 120b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=gpt-oss-120b"
    },
    "qwen3-30b-a3b-thinking-2507-1m": {
      "title": "Qwen3 30b A3b Thinking 2507 1m - IQ4_XS GGUF Model",
      "description": "Download Qwen3 30b A3b Thinking 2507 1m in IQ4_XS quantization format. File size: 15.2 GB. 908 downloads. Direct download from Hugging Face.",
      "keywords": "Qwen3 30b A3b Thinking 2507 1m, IQ4_XS, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Qwen3 30b A3b Thinking 2507 1m",
        "description": "Download Qwen3 30b A3b Thinking 2507 1m in IQ4_XS quantization format. File size: 15.2 GB. 908 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "15.2 GB",
        "downloadUrl": "https://huggingface.co/Orion-zhen/Qwen3-30B-A3B-Thinking-2507-1M-GGUF/resolve/main/Qwen3-30B-A3B-Thinking-2507-1M-IQ4_XS.gguf",
        "url": "https://huggingface.co/Orion-zhen/Qwen3-30B-A3B-Thinking-2507-1M-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 908
        }
      },
      "openGraph": {
        "title": "Qwen3 30b A3b Thinking 2507 1m - GGUF Model Download",
        "description": "Download Qwen3 30b A3b Thinking 2507 1m in IQ4_XS quantization format. File size: 15.2 GB. 908 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=qwen3-30b-a3b-thinking-2507-1m",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Qwen3 30b A3b Thinking 2507 1m GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=qwen3-30b-a3b-thinking-2507-1m"
    },
    "zerofata-ms3-2-paintedfantasy-v2-24b": {
      "title": "Zerofata Ms3.2 Paintedfantasy V2 24b - BF16 GGUF Model",
      "description": "Download Zerofata Ms3.2 Paintedfantasy V2 24b in BF16 quantization format. File size: 43.9 GB. 888 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Zerofata Ms3.2 Paintedfantasy V2 24b, BF16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Zerofata Ms3.2 Paintedfantasy V2 24b",
        "description": "Download Zerofata Ms3.2 Paintedfantasy V2 24b in BF16 quantization format. File size: 43.9 GB. 888 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "43.9 GB",
        "downloadUrl": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v2-24B-GGUF/resolve/main/zerofata_MS3.2-PaintedFantasy-v2-24B-bf16.gguf",
        "url": "https://huggingface.co/bartowski/zerofata_MS3.2-PaintedFantasy-v2-24B-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 888
        }
      },
      "openGraph": {
        "title": "Zerofata Ms3.2 Paintedfantasy V2 24b - GGUF Model Download",
        "description": "Download Zerofata Ms3.2 Paintedfantasy V2 24b in BF16 quantization format. File size: 43.9 GB. 888 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=zerofata-ms3-2-paintedfantasy-v2-24b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Zerofata Ms3.2 Paintedfantasy V2 24b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=zerofata-ms3-2-paintedfantasy-v2-24b"
    },
    "huihui-qwen3-30b-a3b-thinking-2507-abliterated-i1": {
      "title": "Huihui Qwen3 30b A3b Thinking 2507 Abliterated I1 - IQ1_S GGUF Model",
      "description": "Download Huihui Qwen3 30b A3b Thinking 2507 Abliterated I1 in IQ1_S quantization format. File size: 6.0 GB. 852 downloads. 2 likes. Direct download from Hugging Face.",
      "keywords": "Huihui Qwen3 30b A3b Thinking 2507 Abliterated I1, IQ1_S, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Huihui Qwen3 30b A3b Thinking 2507 Abliterated I1",
        "description": "Download Huihui Qwen3 30b A3b Thinking 2507 Abliterated I1 in IQ1_S quantization format. File size: 6.0 GB. 852 downloads. 2 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.0 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Huihui-Qwen3-30B-A3B-Thinking-2507-abliterated-i1-GGUF/resolve/main/Huihui-Qwen3-30B-A3B-Thinking-2507-abliterated.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/Huihui-Qwen3-30B-A3B-Thinking-2507-abliterated-i1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 2
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 852
        }
      },
      "openGraph": {
        "title": "Huihui Qwen3 30b A3b Thinking 2507 Abliterated I1 - GGUF Model Download",
        "description": "Download Huihui Qwen3 30b A3b Thinking 2507 Abliterated I1 in IQ1_S quantization format. File size: 6.0 GB. 852 downloads. 2 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=huihui-qwen3-30b-a3b-thinking-2507-abliterated-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Huihui Qwen3 30b A3b Thinking 2507 Abliterated I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=huihui-qwen3-30b-a3b-thinking-2507-abliterated-i1"
    },
    "valkyrie-49b-v2b": {
      "title": "Valkyrie 49b V2b - Q2_K GGUF Model",
      "description": "Download Valkyrie 49b V2b in Q2_K quantization format. File size: 17.5 GB. 815 downloads. Direct download from Hugging Face.",
      "keywords": "Valkyrie 49b V2b, Q2_K, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Valkyrie 49b V2b",
        "description": "Download Valkyrie 49b V2b in Q2_K quantization format. File size: 17.5 GB. 815 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "17.5 GB",
        "downloadUrl": "https://huggingface.co/BeaverAI/Valkyrie-49B-v2b-GGUF/resolve/main/Valkyrie-49B-v2b-Q2_K.gguf",
        "url": "https://huggingface.co/BeaverAI/Valkyrie-49B-v2b-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 815
        }
      },
      "openGraph": {
        "title": "Valkyrie 49b V2b - GGUF Model Download",
        "description": "Download Valkyrie 49b V2b in Q2_K quantization format. File size: 17.5 GB. 815 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=valkyrie-49b-v2b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Valkyrie 49b V2b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=valkyrie-49b-v2b"
    },
    "allura-org-mn-lyrebird-12b": {
      "title": "Allura Org Mn Lyrebird 12b - BF16 GGUF Model",
      "description": "Download Allura Org Mn Lyrebird 12b in BF16 quantization format. File size: 22.8 GB. 760 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Allura Org Mn Lyrebird 12b, BF16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Allura Org Mn Lyrebird 12b",
        "description": "Download Allura Org Mn Lyrebird 12b in BF16 quantization format. File size: 22.8 GB. 760 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "22.8 GB",
        "downloadUrl": "https://huggingface.co/bartowski/allura-org_MN-Lyrebird-12B-GGUF/resolve/main/allura-org_MN-Lyrebird-12B-bf16.gguf",
        "url": "https://huggingface.co/bartowski/allura-org_MN-Lyrebird-12B-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 760
        }
      },
      "openGraph": {
        "title": "Allura Org Mn Lyrebird 12b - GGUF Model Download",
        "description": "Download Allura Org Mn Lyrebird 12b in BF16 quantization format. File size: 22.8 GB. 760 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=allura-org-mn-lyrebird-12b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Allura Org Mn Lyrebird 12b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=allura-org-mn-lyrebird-12b"
    },
    "helpingai-dhanishtha-2-0-preview-0825": {
      "title": "Helpingai Dhanishtha 2.0 Preview 0825 - BF16 GGUF Model",
      "description": "Download Helpingai Dhanishtha 2.0 Preview 0825 in BF16 quantization format. File size: 27.5 GB. 753 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Helpingai Dhanishtha 2.0 Preview 0825, BF16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Helpingai Dhanishtha 2.0 Preview 0825",
        "description": "Download Helpingai Dhanishtha 2.0 Preview 0825 in BF16 quantization format. File size: 27.5 GB. 753 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "27.5 GB",
        "downloadUrl": "https://huggingface.co/bartowski/HelpingAI_Dhanishtha-2.0-preview-0825-GGUF/resolve/main/HelpingAI_Dhanishtha-2.0-preview-0825-bf16.gguf",
        "url": "https://huggingface.co/bartowski/HelpingAI_Dhanishtha-2.0-preview-0825-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 753
        }
      },
      "openGraph": {
        "title": "Helpingai Dhanishtha 2.0 Preview 0825 - GGUF Model Download",
        "description": "Download Helpingai Dhanishtha 2.0 Preview 0825 in BF16 quantization format. File size: 27.5 GB. 753 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=helpingai-dhanishtha-2-0-preview-0825",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Helpingai Dhanishtha 2.0 Preview 0825 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=helpingai-dhanishtha-2-0-preview-0825"
    },
    "dellamix-12b-i1": {
      "title": "Dellamix 12b I1 - IQ1_S GGUF Model",
      "description": "Download Dellamix 12b I1 in IQ1_S quantization format. File size: 2.8 GB. 718 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Dellamix 12b I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Dellamix 12b I1",
        "description": "Download Dellamix 12b I1 in IQ1_S quantization format. File size: 2.8 GB. 718 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "2.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/DellaMix-12B-i1-GGUF/resolve/main/DellaMix-12B.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/DellaMix-12B-i1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 718
        }
      },
      "openGraph": {
        "title": "Dellamix 12b I1 - GGUF Model Download",
        "description": "Download Dellamix 12b I1 in IQ1_S quantization format. File size: 2.8 GB. 718 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=dellamix-12b-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Dellamix 12b I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=dellamix-12b-i1"
    },
    "llada-1-5-i1": {
      "title": "Llada 1.5 I1 - IQ1_S GGUF Model",
      "description": "Download Llada 1.5 I1 in IQ1_S quantization format. File size: 1.9 GB. 716 downloads. Direct download from Hugging Face.",
      "keywords": "Llada 1.5 I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Llada 1.5 I1",
        "description": "Download Llada 1.5 I1 in IQ1_S quantization format. File size: 1.9 GB. 716 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.9 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/LLaDA-1.5-i1-GGUF/resolve/main/LLaDA-1.5.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/LLaDA-1.5-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 716
        }
      },
      "openGraph": {
        "title": "Llada 1.5 I1 - GGUF Model Download",
        "description": "Download Llada 1.5 I1 in IQ1_S quantization format. File size: 1.9 GB. 716 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=llada-1-5-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Llada 1.5 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=llada-1-5-i1"
    },
    "skywork-mindlink-72b-0801": {
      "title": "Skywork Mindlink 72b 0801 - Q5_K_M GGUF Model",
      "description": "Download Skywork Mindlink 72b 0801 in Q5_K_M quantization format. File size: 13.6 GB. 626 downloads. Direct download from Hugging Face.",
      "keywords": "Skywork Mindlink 72b 0801, Q5_K_M, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Skywork Mindlink 72b 0801",
        "description": "Download Skywork Mindlink 72b 0801 in Q5_K_M quantization format. File size: 13.6 GB. 626 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "13.6 GB",
        "downloadUrl": "https://huggingface.co/bartowski/Skywork_MindLink-72B-0801-GGUF/resolve/main/Skywork_MindLink-72B-0801-Q5_K_M/Skywork_MindLink-72B-0801-Q5_K_M-00002-of-00002.gguf",
        "url": "https://huggingface.co/bartowski/Skywork_MindLink-72B-0801-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 626
        }
      },
      "openGraph": {
        "title": "Skywork Mindlink 72b 0801 - GGUF Model Download",
        "description": "Download Skywork Mindlink 72b 0801 in Q5_K_M quantization format. File size: 13.6 GB. 626 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=skywork-mindlink-72b-0801",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Skywork Mindlink 72b 0801 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=skywork-mindlink-72b-0801"
    },
    "etherealaurora-12b-lorablated-i1": {
      "title": "Etherealaurora 12b Lorablated I1 - IQ1_S GGUF Model",
      "description": "Download Etherealaurora 12b Lorablated I1 in IQ1_S quantization format. File size: 2.8 GB. 625 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Etherealaurora 12b Lorablated I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Etherealaurora 12b Lorablated I1",
        "description": "Download Etherealaurora 12b Lorablated I1 in IQ1_S quantization format. File size: 2.8 GB. 625 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "2.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/EtherealAurora-12B-Lorablated-i1-GGUF/resolve/main/EtherealAurora-12B-Lorablated.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/EtherealAurora-12B-Lorablated-i1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 625
        }
      },
      "openGraph": {
        "title": "Etherealaurora 12b Lorablated I1 - GGUF Model Download",
        "description": "Download Etherealaurora 12b Lorablated I1 in IQ1_S quantization format. File size: 2.8 GB. 625 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=etherealaurora-12b-lorablated-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Etherealaurora 12b Lorablated I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=etherealaurora-12b-lorablated-i1"
    },
    "mindlink-72b-0801": {
      "title": "Mindlink 72b 0801 - Q3_K_L GGUF Model",
      "description": "Download Mindlink 72b 0801 in Q3_K_L quantization format. File size: 36.8 GB. 615 downloads. Direct download from Hugging Face.",
      "keywords": "Mindlink 72b 0801, Q3_K_L, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Mindlink 72b 0801",
        "description": "Download Mindlink 72b 0801 in Q3_K_L quantization format. File size: 36.8 GB. 615 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "36.8 GB",
        "downloadUrl": "https://huggingface.co/lmstudio-community/MindLink-72B-0801-GGUF/resolve/main/MindLink-72B-0801-Q3_K_L.gguf",
        "url": "https://huggingface.co/lmstudio-community/MindLink-72B-0801-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 615
        }
      },
      "openGraph": {
        "title": "Mindlink 72b 0801 - GGUF Model Download",
        "description": "Download Mindlink 72b 0801 in Q3_K_L quantization format. File size: 36.8 GB. 615 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=mindlink-72b-0801",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Mindlink 72b 0801 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=mindlink-72b-0801"
    },
    "gemma3-12b-tolkien-v2-i1": {
      "title": "Gemma3 12b Tolkien V2 I1 - Unknown GGUF Model",
      "description": "Download Gemma3 12b Tolkien V2 I1 in Unknown quantization format. File size: 6.4 GB. 586 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Gemma3 12b Tolkien V2 I1, Unknown, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Gemma3 12b Tolkien V2 I1",
        "description": "Download Gemma3 12b Tolkien V2 I1 in Unknown quantization format. File size: 6.4 GB. 586 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.4 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/gemma3-12b-tolkien_v2-i1-GGUF/resolve/main/gemma3-12b-tolkien_v2.i1-IQ4_NL.gguf",
        "url": "https://huggingface.co/mradermacher/gemma3-12b-tolkien_v2-i1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 586
        }
      },
      "openGraph": {
        "title": "Gemma3 12b Tolkien V2 I1 - GGUF Model Download",
        "description": "Download Gemma3 12b Tolkien V2 I1 in Unknown quantization format. File size: 6.4 GB. 586 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=gemma3-12b-tolkien-v2-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Gemma3 12b Tolkien V2 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=gemma3-12b-tolkien-v2-i1"
    },
    "qwen3-30b-a3b-mixture-2507-i1": {
      "title": "Qwen3 30b A3b Mixture 2507 I1 - IQ1_S GGUF Model",
      "description": "Download Qwen3 30b A3b Mixture 2507 I1 in IQ1_S quantization format. File size: 6.0 GB. 573 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Qwen3 30b A3b Mixture 2507 I1, IQ1_S, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Qwen3 30b A3b Mixture 2507 I1",
        "description": "Download Qwen3 30b A3b Mixture 2507 I1 in IQ1_S quantization format. File size: 6.0 GB. 573 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.0 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Qwen3-30B-A3B-Mixture-2507-i1-GGUF/resolve/main/Qwen3-30B-A3B-Mixture-2507.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/Qwen3-30B-A3B-Mixture-2507-i1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 573
        }
      },
      "openGraph": {
        "title": "Qwen3 30b A3b Mixture 2507 I1 - GGUF Model Download",
        "description": "Download Qwen3 30b A3b Mixture 2507 I1 in IQ1_S quantization format. File size: 6.0 GB. 573 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=qwen3-30b-a3b-mixture-2507-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Qwen3 30b A3b Mixture 2507 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=qwen3-30b-a3b-mixture-2507-i1"
    },
    "qwen3-4b-abliterated-f32s": {
      "title": "Qwen3 4b Abliterated F32s - BF16 GGUF Model",
      "description": "Download Qwen3 4b Abliterated F32s in BF16 quantization format. File size: 7.5 GB. 564 downloads. 2 likes. Direct download from Hugging Face.",
      "keywords": "Qwen3 4b Abliterated F32s, BF16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Qwen3 4b Abliterated F32s",
        "description": "Download Qwen3 4b Abliterated F32s in BF16 quantization format. File size: 7.5 GB. 564 downloads. 2 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "7.5 GB",
        "downloadUrl": "https://huggingface.co/prithivMLmods/Qwen3-4B-abliterated-f32-GGUFs/resolve/main/Qwen3-4B-abliterated.BF16.gguf",
        "url": "https://huggingface.co/prithivMLmods/Qwen3-4B-abliterated-f32-GGUFs",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 2
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 564
        }
      },
      "openGraph": {
        "title": "Qwen3 4b Abliterated F32s - GGUF Model Download",
        "description": "Download Qwen3 4b Abliterated F32s in BF16 quantization format. File size: 7.5 GB. 564 downloads. 2 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=qwen3-4b-abliterated-f32s",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Qwen3 4b Abliterated F32s GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=qwen3-4b-abliterated-f32s"
    },
    "gemma-3-r1-27b-v1a": {
      "title": "Gemma 3 R1 27b V1a - Q2_K GGUF Model",
      "description": "Download Gemma 3 R1 27b V1a in Q2_K quantization format. Gemma model File size: 9.8 GB. 556 downloads. Direct download from Hugging Face.",
      "keywords": "Gemma 3 R1 27b V1a, Q2_K, GGUF model, download, Gemma, Gemma model, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Gemma 3 R1 27b V1a",
        "description": "Download Gemma 3 R1 27b V1a in Q2_K quantization format. Gemma model File size: 9.8 GB. 556 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "9.8 GB",
        "downloadUrl": "https://huggingface.co/BeaverAI/Gemma-3-R1-27B-v1a-GGUF/resolve/main/Gemma-3-R1-27B-v1a-Q2_K.gguf",
        "url": "https://huggingface.co/BeaverAI/Gemma-3-R1-27B-v1a-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 556
        }
      },
      "openGraph": {
        "title": "Gemma 3 R1 27b V1a - GGUF Model Download",
        "description": "Download Gemma 3 R1 27b V1a in Q2_K quantization format. Gemma model File size: 9.8 GB. 556 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=gemma-3-r1-27b-v1a",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Gemma 3 R1 27b V1a GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=gemma-3-r1-27b-v1a"
    },
    "gemma3-12b-tolkien-v3-i1": {
      "title": "Gemma3 12b Tolkien V3 I1 - IQ1_S GGUF Model",
      "description": "Download Gemma3 12b Tolkien V3 I1 in IQ1_S quantization format. File size: 2.7 GB. 546 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Gemma3 12b Tolkien V3 I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Gemma3 12b Tolkien V3 I1",
        "description": "Download Gemma3 12b Tolkien V3 I1 in IQ1_S quantization format. File size: 2.7 GB. 546 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "2.7 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/gemma3-12b-tolkien_v3-i1-GGUF/resolve/main/gemma3-12b-tolkien_v3.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/gemma3-12b-tolkien_v3-i1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 546
        }
      },
      "openGraph": {
        "title": "Gemma3 12b Tolkien V3 I1 - GGUF Model Download",
        "description": "Download Gemma3 12b Tolkien V3 I1 in IQ1_S quantization format. File size: 2.7 GB. 546 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=gemma3-12b-tolkien-v3-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Gemma3 12b Tolkien V3 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=gemma3-12b-tolkien-v3-i1"
    },
    "qwen3-30b-a3b-mixture-2507": {
      "title": "Qwen3 30b A3b Mixture 2507 - Q2_K GGUF Model",
      "description": "Download Qwen3 30b A3b Mixture 2507 in Q2_K quantization format. File size: 10.5 GB. 546 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Qwen3 30b A3b Mixture 2507, Q2_K, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Qwen3 30b A3b Mixture 2507",
        "description": "Download Qwen3 30b A3b Mixture 2507 in Q2_K quantization format. File size: 10.5 GB. 546 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "10.5 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Qwen3-30B-A3B-Mixture-2507-GGUF/resolve/main/Qwen3-30B-A3B-Mixture-2507.Q2_K.gguf",
        "url": "https://huggingface.co/mradermacher/Qwen3-30B-A3B-Mixture-2507-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 546
        }
      },
      "openGraph": {
        "title": "Qwen3 30b A3b Mixture 2507 - GGUF Model Download",
        "description": "Download Qwen3 30b A3b Mixture 2507 in Q2_K quantization format. File size: 10.5 GB. 546 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=qwen3-30b-a3b-mixture-2507",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Qwen3 30b A3b Mixture 2507 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=qwen3-30b-a3b-mixture-2507"
    },
    "eloisa-qwen3-8b-i1": {
      "title": "Eloisa Qwen3 8b I1 - IQ1_S GGUF Model",
      "description": "Download Eloisa Qwen3 8b I1 in IQ1_S quantization format. File size: 2.0 GB. 539 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Eloisa Qwen3 8b I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Eloisa Qwen3 8b I1",
        "description": "Download Eloisa Qwen3 8b I1 in IQ1_S quantization format. File size: 2.0 GB. 539 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "2.0 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Eloisa-Qwen3-8B-i1-GGUF/resolve/main/Eloisa-Qwen3-8B.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/Eloisa-Qwen3-8B-i1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 539
        }
      },
      "openGraph": {
        "title": "Eloisa Qwen3 8b I1 - GGUF Model Download",
        "description": "Download Eloisa Qwen3 8b I1 in IQ1_S quantization format. File size: 2.0 GB. 539 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=eloisa-qwen3-8b-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Eloisa Qwen3 8b I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=eloisa-qwen3-8b-i1"
    },
    "llama-3-8b-3some-v2-regularized-i1": {
      "title": "Llama 3 8b 3some V2 Regularized I1 - IQ1_S GGUF Model",
      "description": "Download Llama 3 8b 3some V2 Regularized I1 in IQ1_S quantization format. Llama model File size: 1.9 GB. 537 downloads. Direct download from Hugging Face.",
      "keywords": "Llama 3 8b 3some V2 Regularized I1, IQ1_S, GGUF model, download, Llama, Llama model, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Llama 3 8b 3some V2 Regularized I1",
        "description": "Download Llama 3 8b 3some V2 Regularized I1 in IQ1_S quantization format. Llama model File size: 1.9 GB. 537 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.9 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Llama-3-8B-3SOME-v2-Regularized-i1-GGUF/resolve/main/Llama-3-8B-3SOME-v2-Regularized.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/Llama-3-8B-3SOME-v2-Regularized-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 537
        }
      },
      "openGraph": {
        "title": "Llama 3 8b 3some V2 Regularized I1 - GGUF Model Download",
        "description": "Download Llama 3 8b 3some V2 Regularized I1 in IQ1_S quantization format. Llama model File size: 1.9 GB. 537 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=llama-3-8b-3some-v2-regularized-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Llama 3 8b 3some V2 Regularized I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=llama-3-8b-3some-v2-regularized-i1"
    },
    "nextcoder-7b-finetuned-i1": {
      "title": "Nextcoder 7b Finetuned I1 - IQ1_S GGUF Model",
      "description": "Download Nextcoder 7b Finetuned I1 in IQ1_S quantization format. File size: 1.8 GB. 508 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Nextcoder 7b Finetuned I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Nextcoder 7b Finetuned I1",
        "description": "Download Nextcoder 7b Finetuned I1 in IQ1_S quantization format. File size: 1.8 GB. 508 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/NextCoder-7B-Finetuned-i1-GGUF/resolve/main/NextCoder-7B-Finetuned.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/NextCoder-7B-Finetuned-i1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 508
        }
      },
      "openGraph": {
        "title": "Nextcoder 7b Finetuned I1 - GGUF Model Download",
        "description": "Download Nextcoder 7b Finetuned I1 in IQ1_S quantization format. File size: 1.8 GB. 508 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=nextcoder-7b-finetuned-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Nextcoder 7b Finetuned I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=nextcoder-7b-finetuned-i1"
    },
    "mingle-1-0-i1": {
      "title": "Mingle 1.0 I1 - IQ1_S GGUF Model",
      "description": "Download Mingle 1.0 I1 in IQ1_S quantization format. File size: 1.8 GB. 492 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Mingle 1.0 I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Mingle 1.0 I1",
        "description": "Download Mingle 1.0 I1 in IQ1_S quantization format. File size: 1.8 GB. 492 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/MINGLE-1.0-i1-GGUF/resolve/main/MINGLE-1.0.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/MINGLE-1.0-i1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 492
        }
      },
      "openGraph": {
        "title": "Mingle 1.0 I1 - GGUF Model Download",
        "description": "Download Mingle 1.0 I1 in IQ1_S quantization format. File size: 1.8 GB. 492 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=mingle-1-0-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Mingle 1.0 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=mingle-1-0-i1"
    },
    "vl-cogito-i1": {
      "title": "Vl Cogito I1 - IQ1_S GGUF Model",
      "description": "Download Vl Cogito I1 in IQ1_S quantization format. File size: 1.8 GB. 492 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Vl Cogito I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Vl Cogito I1",
        "description": "Download Vl Cogito I1 in IQ1_S quantization format. File size: 1.8 GB. 492 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/VL-Cogito-i1-GGUF/resolve/main/VL-Cogito.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/VL-Cogito-i1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 492
        }
      },
      "openGraph": {
        "title": "Vl Cogito I1 - GGUF Model Download",
        "description": "Download Vl Cogito I1 in IQ1_S quantization format. File size: 1.8 GB. 492 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=vl-cogito-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Vl Cogito I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=vl-cogito-i1"
    },
    "valkyrie-49b-v2a": {
      "title": "Valkyrie 49b V2a - Q2_K GGUF Model",
      "description": "Download Valkyrie 49b V2a in Q2_K quantization format. File size: 17.5 GB. 487 downloads. Direct download from Hugging Face.",
      "keywords": "Valkyrie 49b V2a, Q2_K, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Valkyrie 49b V2a",
        "description": "Download Valkyrie 49b V2a in Q2_K quantization format. File size: 17.5 GB. 487 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "17.5 GB",
        "downloadUrl": "https://huggingface.co/BeaverAI/Valkyrie-49B-v2a-GGUF/resolve/main/Valkyrie-49B-v2a-Q2_K.gguf",
        "url": "https://huggingface.co/BeaverAI/Valkyrie-49B-v2a-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 487
        }
      },
      "openGraph": {
        "title": "Valkyrie 49b V2a - GGUF Model Download",
        "description": "Download Valkyrie 49b V2a in Q2_K quantization format. File size: 17.5 GB. 487 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=valkyrie-49b-v2a",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Valkyrie 49b V2a GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=valkyrie-49b-v2a"
    },
    "openai-gpt-oss-20b-mxfp4-experimental": {
      "title": "Openai Gpt Oss 20b Mxfp4 Experimental - Unknown GGUF Model",
      "description": "Download Openai Gpt Oss 20b Mxfp4 Experimental in Unknown quantization format. File size: 11.3 GB. 440 downloads. 5 likes. Direct download from Hugging Face.",
      "keywords": "Openai Gpt Oss 20b Mxfp4 Experimental, Unknown, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Openai Gpt Oss 20b Mxfp4 Experimental",
        "description": "Download Openai Gpt Oss 20b Mxfp4 Experimental in Unknown quantization format. File size: 11.3 GB. 440 downloads. 5 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "11.3 GB",
        "downloadUrl": "https://huggingface.co/bartowski/openai_gpt-oss-20b-GGUF-MXFP4-Experimental/resolve/main/openai_gpt-oss-20b-MXFP4.gguf",
        "url": "https://huggingface.co/bartowski/openai_gpt-oss-20b-GGUF-MXFP4-Experimental",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 5
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 440
        }
      },
      "openGraph": {
        "title": "Openai Gpt Oss 20b Mxfp4 Experimental - GGUF Model Download",
        "description": "Download Openai Gpt Oss 20b Mxfp4 Experimental in Unknown quantization format. File size: 11.3 GB. 440 downloads. 5 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=openai-gpt-oss-20b-mxfp4-experimental",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Openai Gpt Oss 20b Mxfp4 Experimental GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=openai-gpt-oss-20b-mxfp4-experimental"
    },
    "sapphira-l3-3-70b-0-1-i1": {
      "title": "Sapphira L3.3 70b 0.1 I1 - IQ1_S GGUF Model",
      "description": "Download Sapphira L3.3 70b 0.1 I1 in IQ1_S quantization format. File size: 14.3 GB. 416 downloads. Direct download from Hugging Face.",
      "keywords": "Sapphira L3.3 70b 0.1 I1, IQ1_S, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Sapphira L3.3 70b 0.1 I1",
        "description": "Download Sapphira L3.3 70b 0.1 I1 in IQ1_S quantization format. File size: 14.3 GB. 416 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "14.3 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Sapphira-L3.3-70b-0.1-i1-GGUF/resolve/main/Sapphira-L3.3-70b-0.1.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/Sapphira-L3.3-70b-0.1-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 416
        }
      },
      "openGraph": {
        "title": "Sapphira L3.3 70b 0.1 I1 - GGUF Model Download",
        "description": "Download Sapphira L3.3 70b 0.1 I1 in IQ1_S quantization format. File size: 14.3 GB. 416 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=sapphira-l3-3-70b-0-1-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Sapphira L3.3 70b 0.1 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=sapphira-l3-3-70b-0-1-i1"
    },
    "qwen3-53b-a3b-2507-thinking-total-recall-v2-master-coder-i1": {
      "title": "Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder I1 - IQ1_S GGUF Model",
      "description": "Download Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder I1 in IQ1_S quantization format. File size: 10.2 GB. 391 downloads. Direct download from Hugging Face.",
      "keywords": "Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder I1, IQ1_S, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder I1",
        "description": "Download Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder I1 in IQ1_S quantization format. File size: 10.2 GB. 391 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "10.2 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Qwen3-53B-A3B-2507-THINKING-TOTAL-RECALL-v2-MASTER-CODER-i1-GGUF/resolve/main/Qwen3-53B-A3B-2507-THINKING-TOTAL-RECALL-v2-MASTER-CODER.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/Qwen3-53B-A3B-2507-THINKING-TOTAL-RECALL-v2-MASTER-CODER-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 391
        }
      },
      "openGraph": {
        "title": "Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder I1 - GGUF Model Download",
        "description": "Download Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder I1 in IQ1_S quantization format. File size: 10.2 GB. 391 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=qwen3-53b-a3b-2507-thinking-total-recall-v2-master-coder-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=qwen3-53b-a3b-2507-thinking-total-recall-v2-master-coder-i1"
    },
    "cydonia-r1-24b-v4": {
      "title": "Cydonia R1 24b V4 - Q2_K GGUF Model",
      "description": "Download Cydonia R1 24b V4 in Q2_K quantization format. File size: 8.3 GB. 376 downloads. Direct download from Hugging Face.",
      "keywords": "Cydonia R1 24b V4, Q2_K, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Cydonia R1 24b V4",
        "description": "Download Cydonia R1 24b V4 in Q2_K quantization format. File size: 8.3 GB. 376 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "8.3 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Cydonia-R1-24B-v4-GGUF/resolve/main/Cydonia-R1-24B-v4.Q2_K.gguf",
        "url": "https://huggingface.co/mradermacher/Cydonia-R1-24B-v4-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 376
        }
      },
      "openGraph": {
        "title": "Cydonia R1 24b V4 - GGUF Model Download",
        "description": "Download Cydonia R1 24b V4 in Q2_K quantization format. File size: 8.3 GB. 376 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=cydonia-r1-24b-v4",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Cydonia R1 24b V4 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=cydonia-r1-24b-v4"
    },
    "gemma-3-r1-27b-v1": {
      "title": "Gemma 3 R1 27b V1 - Q2_K GGUF Model",
      "description": "Download Gemma 3 R1 27b V1 in Q2_K quantization format. Gemma model File size: 9.8 GB. 371 downloads. 3 likes. Direct download from Hugging Face.",
      "keywords": "Gemma 3 R1 27b V1, Q2_K, GGUF model, download, Gemma, Gemma model, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Gemma 3 R1 27b V1",
        "description": "Download Gemma 3 R1 27b V1 in Q2_K quantization format. Gemma model File size: 9.8 GB. 371 downloads. 3 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "9.8 GB",
        "downloadUrl": "https://huggingface.co/TheDrummer/Gemma-3-R1-27B-v1-GGUF/resolve/main/Gemma-3-R1-27B-v1b-Q2_K.gguf",
        "url": "https://huggingface.co/TheDrummer/Gemma-3-R1-27B-v1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 3
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 371
        }
      },
      "openGraph": {
        "title": "Gemma 3 R1 27b V1 - GGUF Model Download",
        "description": "Download Gemma 3 R1 27b V1 in Q2_K quantization format. Gemma model File size: 9.8 GB. 371 downloads. 3 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=gemma-3-r1-27b-v1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Gemma 3 R1 27b V1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=gemma-3-r1-27b-v1"
    },
    "qwen3-4b-valiant-polaris-f32": {
      "title": "Qwen3 4b Valiant Polaris F32 - BF16 GGUF Model",
      "description": "Download Qwen3 4b Valiant Polaris F32 in BF16 quantization format. File size: 7.5 GB. 370 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Qwen3 4b Valiant Polaris F32, BF16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Qwen3 4b Valiant Polaris F32",
        "description": "Download Qwen3 4b Valiant Polaris F32 in BF16 quantization format. File size: 7.5 GB. 370 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "7.5 GB",
        "downloadUrl": "https://huggingface.co/prithivMLmods/Qwen3-4B-Valiant-Polaris-f32-GGUF/resolve/main/ Qwen3-4B-Valiant-Polaris.BF16.gguf",
        "url": "https://huggingface.co/prithivMLmods/Qwen3-4B-Valiant-Polaris-f32-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 370
        }
      },
      "openGraph": {
        "title": "Qwen3 4b Valiant Polaris F32 - GGUF Model Download",
        "description": "Download Qwen3 4b Valiant Polaris F32 in BF16 quantization format. File size: 7.5 GB. 370 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=qwen3-4b-valiant-polaris-f32",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Qwen3 4b Valiant Polaris F32 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=qwen3-4b-valiant-polaris-f32"
    },
    "qwen3-53b-a3b-2507-thinking-total-recall-v2-master-coder": {
      "title": "Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder - Q2_K GGUF Model",
      "description": "Download Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder in Q2_K quantization format. File size: 18.1 GB. 363 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder, Q2_K, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder",
        "description": "Download Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder in Q2_K quantization format. File size: 18.1 GB. 363 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "18.1 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Qwen3-53B-A3B-2507-THINKING-TOTAL-RECALL-v2-MASTER-CODER-GGUF/resolve/main/Qwen3-53B-A3B-2507-THINKING-TOTAL-RECALL-v2-MASTER-CODER.Q2_K.gguf",
        "url": "https://huggingface.co/mradermacher/Qwen3-53B-A3B-2507-THINKING-TOTAL-RECALL-v2-MASTER-CODER-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 363
        }
      },
      "openGraph": {
        "title": "Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder - GGUF Model Download",
        "description": "Download Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder in Q2_K quantization format. File size: 18.1 GB. 363 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=qwen3-53b-a3b-2507-thinking-total-recall-v2-master-coder",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Qwen3 53b A3b 2507 Thinking Total Recall V2 Master Coder GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=qwen3-53b-a3b-2507-thinking-total-recall-v2-master-coder"
    },
    "aquif-3-moe-17b-a2-8b-i1": {
      "title": "Aquif 3 Moe 17b A2.8b I1 - IQ2_XXS GGUF Model",
      "description": "Download Aquif 3 Moe 17b A2.8b I1 in IQ2_XXS quantization format. File size: 5.6 GB. 354 downloads. Direct download from Hugging Face.",
      "keywords": "Aquif 3 Moe 17b A2.8b I1, IQ2_XXS, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Aquif 3 Moe 17b A2.8b I1",
        "description": "Download Aquif 3 Moe 17b A2.8b I1 in IQ2_XXS quantization format. File size: 5.6 GB. 354 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "5.6 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/aquif-3-moe-17b-a2.8b-i1-GGUF/resolve/main/aquif-3-moe-17b-a2.8b.i1-IQ2_XXS.gguf",
        "url": "https://huggingface.co/mradermacher/aquif-3-moe-17b-a2.8b-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 354
        }
      },
      "openGraph": {
        "title": "Aquif 3 Moe 17b A2.8b I1 - GGUF Model Download",
        "description": "Download Aquif 3 Moe 17b A2.8b I1 in IQ2_XXS quantization format. File size: 5.6 GB. 354 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=aquif-3-moe-17b-a2-8b-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Aquif 3 Moe 17b A2.8b I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=aquif-3-moe-17b-a2-8b-i1"
    },
    "hydracoder-i1": {
      "title": "Hydracoder I1 - IQ1_S GGUF Model",
      "description": "Download Hydracoder I1 in IQ1_S quantization format. File size: 6.0 GB. 344 downloads. Direct download from Hugging Face.",
      "keywords": "Hydracoder I1, IQ1_S, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Hydracoder I1",
        "description": "Download Hydracoder I1 in IQ1_S quantization format. File size: 6.0 GB. 344 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.0 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/HydraCoder-i1-GGUF/resolve/main/HydraCoder.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/HydraCoder-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 344
        }
      },
      "openGraph": {
        "title": "Hydracoder I1 - GGUF Model Download",
        "description": "Download Hydracoder I1 in IQ1_S quantization format. File size: 6.0 GB. 344 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=hydracoder-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Hydracoder I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=hydracoder-i1"
    },
    "gemma-3n-e2b-just-chatty": {
      "title": "Gemma 3n E2b Just Chatty - F16 GGUF Model",
      "description": "Download Gemma 3n E2b Just Chatty in F16 quantization format. Gemma model File size: 8.3 GB. 331 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Gemma 3n E2b Just Chatty, F16, GGUF model, download, Gemma, Gemma model, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Gemma 3n E2b Just Chatty",
        "description": "Download Gemma 3n E2b Just Chatty in F16 quantization format. Gemma model File size: 8.3 GB. 331 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "8.3 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/gemma-3N-E2B-Just-Chatty-GGUF/resolve/main/gemma-3N-E2B-Just-Chatty.f16.gguf",
        "url": "https://huggingface.co/mradermacher/gemma-3N-E2B-Just-Chatty-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 331
        }
      },
      "openGraph": {
        "title": "Gemma 3n E2b Just Chatty - GGUF Model Download",
        "description": "Download Gemma 3n E2b Just Chatty in F16 quantization format. Gemma model File size: 8.3 GB. 331 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=gemma-3n-e2b-just-chatty",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Gemma 3n E2b Just Chatty GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=gemma-3n-e2b-just-chatty"
    },
    "llama-pllum-8b-base-250801-i1": {
      "title": "Llama Pllum 8b Base 250801 I1 - Q6_K GGUF Model",
      "description": "Download Llama Pllum 8b Base 250801 I1 in Q6_K quantization format. Llama model File size: 6.1 GB. 330 downloads. Direct download from Hugging Face.",
      "keywords": "Llama Pllum 8b Base 250801 I1, Q6_K, GGUF model, download, Llama, Llama model, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Llama Pllum 8b Base 250801 I1",
        "description": "Download Llama Pllum 8b Base 250801 I1 in Q6_K quantization format. Llama model File size: 6.1 GB. 330 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.1 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Llama-PLLuM-8B-base-250801-i1-GGUF/resolve/main/Llama-PLLuM-8B-base-250801.i1-Q6_K.gguf",
        "url": "https://huggingface.co/mradermacher/Llama-PLLuM-8B-base-250801-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 330
        }
      },
      "openGraph": {
        "title": "Llama Pllum 8b Base 250801 I1 - GGUF Model Download",
        "description": "Download Llama Pllum 8b Base 250801 I1 in Q6_K quantization format. Llama model File size: 6.1 GB. 330 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=llama-pllum-8b-base-250801-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Llama Pllum 8b Base 250801 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=llama-pllum-8b-base-250801-i1"
    },
    "mmada-8b-mixcot-i1": {
      "title": "Mmada 8b Mixcot I1 - IQ1_S GGUF Model",
      "description": "Download Mmada 8b Mixcot I1 in IQ1_S quantization format. File size: 1.9 GB. 330 downloads. Direct download from Hugging Face.",
      "keywords": "Mmada 8b Mixcot I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Mmada 8b Mixcot I1",
        "description": "Download Mmada 8b Mixcot I1 in IQ1_S quantization format. File size: 1.9 GB. 330 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.9 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/MMaDA-8B-MixCoT-i1-GGUF/resolve/main/MMaDA-8B-MixCoT.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/MMaDA-8B-MixCoT-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 330
        }
      },
      "openGraph": {
        "title": "Mmada 8b Mixcot I1 - GGUF Model Download",
        "description": "Download Mmada 8b Mixcot I1 in IQ1_S quantization format. File size: 1.9 GB. 330 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=mmada-8b-mixcot-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Mmada 8b Mixcot I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=mmada-8b-mixcot-i1"
    },
    "pllum-12b-base-250801-i1": {
      "title": "Pllum 12b Base 250801 I1 - Q6_K GGUF Model",
      "description": "Download Pllum 12b Base 250801 I1 in Q6_K quantization format. File size: 9.4 GB. 324 downloads. Direct download from Hugging Face.",
      "keywords": "Pllum 12b Base 250801 I1, Q6_K, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Pllum 12b Base 250801 I1",
        "description": "Download Pllum 12b Base 250801 I1 in Q6_K quantization format. File size: 9.4 GB. 324 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "9.4 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/PLLuM-12B-base-250801-i1-GGUF/resolve/main/PLLuM-12B-base-250801.i1-Q6_K.gguf",
        "url": "https://huggingface.co/mradermacher/PLLuM-12B-base-250801-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 324
        }
      },
      "openGraph": {
        "title": "Pllum 12b Base 250801 I1 - GGUF Model Download",
        "description": "Download Pllum 12b Base 250801 I1 in Q6_K quantization format. File size: 9.4 GB. 324 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=pllum-12b-base-250801-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Pllum 12b Base 250801 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=pllum-12b-base-250801-i1"
    },
    "hydramind-i1": {
      "title": "Hydramind I1 - IQ1_S GGUF Model",
      "description": "Download Hydramind I1 in IQ1_S quantization format. File size: 6.0 GB. 321 downloads. Direct download from Hugging Face.",
      "keywords": "Hydramind I1, IQ1_S, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Hydramind I1",
        "description": "Download Hydramind I1 in IQ1_S quantization format. File size: 6.0 GB. 321 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.0 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/HydraMind-i1-GGUF/resolve/main/HydraMind.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/HydraMind-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 321
        }
      },
      "openGraph": {
        "title": "Hydramind I1 - GGUF Model Download",
        "description": "Download Hydramind I1 in IQ1_S quantization format. File size: 6.0 GB. 321 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=hydramind-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Hydramind I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=hydramind-i1"
    },
    "llada-8b-tools-i1": {
      "title": "Llada 8b Tools I1 - IQ1_S GGUF Model",
      "description": "Download Llada 8b Tools I1 in IQ1_S quantization format. File size: 1.9 GB. 319 downloads. Direct download from Hugging Face.",
      "keywords": "Llada 8b Tools I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Llada 8b Tools I1",
        "description": "Download Llada 8b Tools I1 in IQ1_S quantization format. File size: 1.9 GB. 319 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.9 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/LLaDA-8B-Tools-i1-GGUF/resolve/main/LLaDA-8B-Tools.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/LLaDA-8B-Tools-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 319
        }
      },
      "openGraph": {
        "title": "Llada 8b Tools I1 - GGUF Model Download",
        "description": "Download Llada 8b Tools I1 in IQ1_S quantization format. File size: 1.9 GB. 319 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=llada-8b-tools-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Llada 8b Tools I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=llada-8b-tools-i1"
    },
    "llama-pllum-70b-base-250801-i1": {
      "title": "Llama Pllum 70b Base 250801 I1 - Q5_K_M GGUF Model",
      "description": "Download Llama Pllum 70b Base 250801 I1 in Q5_K_M quantization format. Llama model File size: 46.5 GB. 319 downloads. Direct download from Hugging Face.",
      "keywords": "Llama Pllum 70b Base 250801 I1, Q5_K_M, GGUF model, download, Llama, Llama model, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Llama Pllum 70b Base 250801 I1",
        "description": "Download Llama Pllum 70b Base 250801 I1 in Q5_K_M quantization format. Llama model File size: 46.5 GB. 319 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "46.5 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Llama-PLLuM-70B-base-250801-i1-GGUF/resolve/main/Llama-PLLuM-70B-base-250801.i1-Q5_K_M.gguf",
        "url": "https://huggingface.co/mradermacher/Llama-PLLuM-70B-base-250801-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 319
        }
      },
      "openGraph": {
        "title": "Llama Pllum 70b Base 250801 I1 - GGUF Model Download",
        "description": "Download Llama Pllum 70b Base 250801 I1 in Q5_K_M quantization format. Llama model File size: 46.5 GB. 319 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=llama-pllum-70b-base-250801-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Llama Pllum 70b Base 250801 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=llama-pllum-70b-base-250801-i1"
    },
    "eloisa-qwen3-8b": {
      "title": "Eloisa Qwen3 8b - F16 GGUF Model",
      "description": "Download Eloisa Qwen3 8b in F16 quantization format. File size: 15.3 GB. 314 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Eloisa Qwen3 8b, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Eloisa Qwen3 8b",
        "description": "Download Eloisa Qwen3 8b in F16 quantization format. File size: 15.3 GB. 314 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "15.3 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Eloisa-Qwen3-8B-GGUF/resolve/main/Eloisa-Qwen3-8B.f16.gguf",
        "url": "https://huggingface.co/mradermacher/Eloisa-Qwen3-8B-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 314
        }
      },
      "openGraph": {
        "title": "Eloisa Qwen3 8b - GGUF Model Download",
        "description": "Download Eloisa Qwen3 8b in F16 quantization format. File size: 15.3 GB. 314 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=eloisa-qwen3-8b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Eloisa Qwen3 8b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=eloisa-qwen3-8b"
    },
    "mmada-8b-pretrain-i1": {
      "title": "Mmada 8b Pretrain I1 - IQ1_S GGUF Model",
      "description": "Download Mmada 8b Pretrain I1 in IQ1_S quantization format. File size: 1.9 GB. 314 downloads. Direct download from Hugging Face.",
      "keywords": "Mmada 8b Pretrain I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Mmada 8b Pretrain I1",
        "description": "Download Mmada 8b Pretrain I1 in IQ1_S quantization format. File size: 1.9 GB. 314 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.9 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/MMaDA-8B-Pretrain-i1-GGUF/resolve/main/MMaDA-8B-Pretrain.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/MMaDA-8B-Pretrain-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 314
        }
      },
      "openGraph": {
        "title": "Mmada 8b Pretrain I1 - GGUF Model Download",
        "description": "Download Mmada 8b Pretrain I1 in IQ1_S quantization format. File size: 1.9 GB. 314 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=mmada-8b-pretrain-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Mmada 8b Pretrain I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=mmada-8b-pretrain-i1"
    },
    "diff-llm-i1": {
      "title": "Diff Llm I1 - IQ1_S GGUF Model",
      "description": "Download Diff Llm I1 in IQ1_S quantization format. File size: 1.9 GB. 313 downloads. Direct download from Hugging Face.",
      "keywords": "Diff Llm I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Diff Llm I1",
        "description": "Download Diff Llm I1 in IQ1_S quantization format. File size: 1.9 GB. 313 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.9 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Diff-llm-i1-GGUF/resolve/main/Diff-llm.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/Diff-llm-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 313
        }
      },
      "openGraph": {
        "title": "Diff Llm I1 - GGUF Model Download",
        "description": "Download Diff Llm I1 in IQ1_S quantization format. File size: 1.9 GB. 313 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=diff-llm-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Diff Llm I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=diff-llm-i1"
    },
    "gemma3-12b-tolkien-v3": {
      "title": "Gemma3 12b Tolkien V3 - F16 GGUF Model",
      "description": "Download Gemma3 12b Tolkien V3 in F16 quantization format. File size: 815 MB. 311 downloads. 2 likes. Direct download from Hugging Face.",
      "keywords": "Gemma3 12b Tolkien V3, F16, GGUF model, download, small model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Gemma3 12b Tolkien V3",
        "description": "Download Gemma3 12b Tolkien V3 in F16 quantization format. File size: 815 MB. 311 downloads. 2 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "815 MB",
        "downloadUrl": "https://huggingface.co/mradermacher/gemma3-12b-tolkien_v3-GGUF/resolve/main/gemma3-12b-tolkien_v3.mmproj-f16.gguf",
        "url": "https://huggingface.co/mradermacher/gemma3-12b-tolkien_v3-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 2
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 311
        }
      },
      "openGraph": {
        "title": "Gemma3 12b Tolkien V3 - GGUF Model Download",
        "description": "Download Gemma3 12b Tolkien V3 in F16 quantization format. File size: 815 MB. 311 downloads. 2 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=gemma3-12b-tolkien-v3",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Gemma3 12b Tolkien V3 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=gemma3-12b-tolkien-v3"
    },
    "arc-teacher-8b-i1": {
      "title": "Arc Teacher 8b I1 - IQ1_S GGUF Model",
      "description": "Download Arc Teacher 8b I1 in IQ1_S quantization format. File size: 2.0 GB. 311 downloads. Direct download from Hugging Face.",
      "keywords": "Arc Teacher 8b I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Arc Teacher 8b I1",
        "description": "Download Arc Teacher 8b I1 in IQ1_S quantization format. File size: 2.0 GB. 311 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "2.0 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/arc-teacher-8b-i1-GGUF/resolve/main/arc-teacher-8b.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/arc-teacher-8b-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 311
        }
      },
      "openGraph": {
        "title": "Arc Teacher 8b I1 - GGUF Model Download",
        "description": "Download Arc Teacher 8b I1 in IQ1_S quantization format. File size: 2.0 GB. 311 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=arc-teacher-8b-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Arc Teacher 8b I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=arc-teacher-8b-i1"
    },
    "mmada-8b-base-i1": {
      "title": "Mmada 8b Base I1 - Q6_K GGUF Model",
      "description": "Download Mmada 8b Base I1 in Q6_K quantization format. File size: 6.2 GB. 310 downloads. Direct download from Hugging Face.",
      "keywords": "Mmada 8b Base I1, Q6_K, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Mmada 8b Base I1",
        "description": "Download Mmada 8b Base I1 in Q6_K quantization format. File size: 6.2 GB. 310 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.2 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/MMaDA-8B-Base-i1-GGUF/resolve/main/MMaDA-8B-Base.i1-Q6_K.gguf",
        "url": "https://huggingface.co/mradermacher/MMaDA-8B-Base-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 310
        }
      },
      "openGraph": {
        "title": "Mmada 8b Base I1 - GGUF Model Download",
        "description": "Download Mmada 8b Base I1 in Q6_K quantization format. File size: 6.2 GB. 310 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=mmada-8b-base-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Mmada 8b Base I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=mmada-8b-base-i1"
    },
    "qwen3-4b-nyx-v3-i1": {
      "title": "Qwen3 4b Nyx V3 I1 - Q2_K GGUF Model",
      "description": "Download Qwen3 4b Nyx V3 I1 in Q2_K quantization format. File size: 1.7 GB. 307 downloads. Direct download from Hugging Face.",
      "keywords": "Qwen3 4b Nyx V3 I1, Q2_K, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Qwen3 4b Nyx V3 I1",
        "description": "Download Qwen3 4b Nyx V3 I1 in Q2_K quantization format. File size: 1.7 GB. 307 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.7 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Qwen3-4B-Nyx-V3-i1-GGUF/resolve/main/Qwen3-4B-Nyx-V3.i1-Q2_K.gguf",
        "url": "https://huggingface.co/mradermacher/Qwen3-4B-Nyx-V3-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 307
        }
      },
      "openGraph": {
        "title": "Qwen3 4b Nyx V3 I1 - GGUF Model Download",
        "description": "Download Qwen3 4b Nyx V3 I1 in Q2_K quantization format. File size: 1.7 GB. 307 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=qwen3-4b-nyx-v3-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Qwen3 4b Nyx V3 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=qwen3-4b-nyx-v3-i1"
    },
    "camel-doc-ocr-080125-i1": {
      "title": "Camel Doc Ocr 080125 I1 - IQ1_S GGUF Model",
      "description": "Download Camel Doc Ocr 080125 I1 in IQ1_S quantization format. File size: 1.8 GB. 306 downloads. Direct download from Hugging Face.",
      "keywords": "Camel Doc Ocr 080125 I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Camel Doc Ocr 080125 I1",
        "description": "Download Camel Doc Ocr 080125 I1 in IQ1_S quantization format. File size: 1.8 GB. 306 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Camel-Doc-OCR-080125-i1-GGUF/resolve/main/Camel-Doc-OCR-080125.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/Camel-Doc-OCR-080125-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 306
        }
      },
      "openGraph": {
        "title": "Camel Doc Ocr 080125 I1 - GGUF Model Download",
        "description": "Download Camel Doc Ocr 080125 I1 in IQ1_S quantization format. File size: 1.8 GB. 306 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=camel-doc-ocr-080125-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Camel Doc Ocr 080125 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=camel-doc-ocr-080125-i1"
    },
    "gemma2-obsidianlight-9b-i1": {
      "title": "Gemma2 Obsidianlight 9b I1 - IQ1_S GGUF Model",
      "description": "Download Gemma2 Obsidianlight 9b I1 in IQ1_S quantization format. File size: 2.2 GB. 300 downloads. Direct download from Hugging Face.",
      "keywords": "Gemma2 Obsidianlight 9b I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Gemma2 Obsidianlight 9b I1",
        "description": "Download Gemma2 Obsidianlight 9b I1 in IQ1_S quantization format. File size: 2.2 GB. 300 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "2.2 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Gemma2-ObsidianLight-9B-i1-GGUF/resolve/main/Gemma2-ObsidianLight-9B.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/Gemma2-ObsidianLight-9B-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 300
        }
      },
      "openGraph": {
        "title": "Gemma2 Obsidianlight 9b I1 - GGUF Model Download",
        "description": "Download Gemma2 Obsidianlight 9b I1 in IQ1_S quantization format. File size: 2.2 GB. 300 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=gemma2-obsidianlight-9b-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Gemma2 Obsidianlight 9b I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=gemma2-obsidianlight-9b-i1"
    },
    "nextcoder-7b-finetuned": {
      "title": "Nextcoder 7b Finetuned - F16 GGUF Model",
      "description": "Download Nextcoder 7b Finetuned in F16 quantization format. File size: 14.2 GB. 298 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Nextcoder 7b Finetuned, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Nextcoder 7b Finetuned",
        "description": "Download Nextcoder 7b Finetuned in F16 quantization format. File size: 14.2 GB. 298 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "14.2 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/NextCoder-7B-Finetuned-GGUF/resolve/main/NextCoder-7B-Finetuned.f16.gguf",
        "url": "https://huggingface.co/mradermacher/NextCoder-7B-Finetuned-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 298
        }
      },
      "openGraph": {
        "title": "Nextcoder 7b Finetuned - GGUF Model Download",
        "description": "Download Nextcoder 7b Finetuned in F16 quantization format. File size: 14.2 GB. 298 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=nextcoder-7b-finetuned",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Nextcoder 7b Finetuned GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=nextcoder-7b-finetuned"
    },
    "flux-1-dev-flux-krea-blaze-v1": {
      "title": "Flux.1 Dev Flux Krea Blaze V1 - Q2_K GGUF Model",
      "description": "Download Flux.1 Dev Flux Krea Blaze V1 in Q2_K quantization format. File size: 3.7 GB. 297 downloads. 3 likes. Direct download from Hugging Face.",
      "keywords": "Flux.1 Dev Flux Krea Blaze V1, Q2_K, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Flux.1 Dev Flux Krea Blaze V1",
        "description": "Download Flux.1 Dev Flux Krea Blaze V1 in Q2_K quantization format. File size: 3.7 GB. 297 downloads. 3 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "3.7 GB",
        "downloadUrl": "https://huggingface.co/belisarius/FLUX.1-dev-FLUX-KREA-BLAZE-v1-GGUF/resolve/main/FLUX-KREA-BLAZE-v1-Q2_K.gguf",
        "url": "https://huggingface.co/belisarius/FLUX.1-dev-FLUX-KREA-BLAZE-v1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 3
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 297
        }
      },
      "openGraph": {
        "title": "Flux.1 Dev Flux Krea Blaze V1 - GGUF Model Download",
        "description": "Download Flux.1 Dev Flux Krea Blaze V1 in Q2_K quantization format. File size: 3.7 GB. 297 downloads. 3 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=flux-1-dev-flux-krea-blaze-v1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Flux.1 Dev Flux Krea Blaze V1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=flux-1-dev-flux-krea-blaze-v1"
    },
    "llada-8b-base-i1": {
      "title": "Llada 8b Base I1 - Q6_K GGUF Model",
      "description": "Download Llada 8b Base I1 in Q6_K quantization format. File size: 6.1 GB. 296 downloads. Direct download from Hugging Face.",
      "keywords": "Llada 8b Base I1, Q6_K, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Llada 8b Base I1",
        "description": "Download Llada 8b Base I1 in Q6_K quantization format. File size: 6.1 GB. 296 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.1 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/LLaDA-8B-Base-i1-GGUF/resolve/main/LLaDA-8B-Base.i1-Q6_K.gguf",
        "url": "https://huggingface.co/mradermacher/LLaDA-8B-Base-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 296
        }
      },
      "openGraph": {
        "title": "Llada 8b Base I1 - GGUF Model Download",
        "description": "Download Llada 8b Base I1 in Q6_K quantization format. File size: 6.1 GB. 296 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=llada-8b-base-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Llada 8b Base I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=llada-8b-base-i1"
    },
    "qwen3-8b-physics-i1": {
      "title": "Qwen3 8b Physics I1 - IQ1_S GGUF Model",
      "description": "Download Qwen3 8b Physics I1 in IQ1_S quantization format. File size: 2.0 GB. 295 downloads. Direct download from Hugging Face.",
      "keywords": "Qwen3 8b Physics I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Qwen3 8b Physics I1",
        "description": "Download Qwen3 8b Physics I1 in IQ1_S quantization format. File size: 2.0 GB. 295 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "2.0 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/qwen3-8b-physics-i1-GGUF/resolve/main/qwen3-8b-physics.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/qwen3-8b-physics-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 295
        }
      },
      "openGraph": {
        "title": "Qwen3 8b Physics I1 - GGUF Model Download",
        "description": "Download Qwen3 8b Physics I1 in IQ1_S quantization format. File size: 2.0 GB. 295 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=qwen3-8b-physics-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Qwen3 8b Physics I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=qwen3-8b-physics-i1"
    },
    "graph-r1-7b-i1": {
      "title": "Graph R1 7b I1 - IQ1_S GGUF Model",
      "description": "Download Graph R1 7b I1 in IQ1_S quantization format. File size: 1.8 GB. 293 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Graph R1 7b I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Graph R1 7b I1",
        "description": "Download Graph R1 7b I1 in IQ1_S quantization format. File size: 1.8 GB. 293 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Graph-R1-7B-i1-GGUF/resolve/main/Graph-R1-7B.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/Graph-R1-7B-i1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 293
        }
      },
      "openGraph": {
        "title": "Graph R1 7b I1 - GGUF Model Download",
        "description": "Download Graph R1 7b I1 in IQ1_S quantization format. File size: 1.8 GB. 293 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=graph-r1-7b-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Graph R1 7b I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=graph-r1-7b-i1"
    },
    "qwen3-32b-v3-i1": {
      "title": "Qwen3 32b V3 I1 - IQ1_S GGUF Model",
      "description": "Download Qwen3 32b V3 I1 in IQ1_S quantization format. File size: 6.8 GB. 293 downloads. Direct download from Hugging Face.",
      "keywords": "Qwen3 32b V3 I1, IQ1_S, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Qwen3 32b V3 I1",
        "description": "Download Qwen3 32b V3 I1 in IQ1_S quantization format. File size: 6.8 GB. 293 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/qwen3-32b-v3-i1-GGUF/resolve/main/qwen3-32b-v3.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/qwen3-32b-v3-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 293
        }
      },
      "openGraph": {
        "title": "Qwen3 32b V3 I1 - GGUF Model Download",
        "description": "Download Qwen3 32b V3 I1 in IQ1_S quantization format. File size: 6.8 GB. 293 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=qwen3-32b-v3-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Qwen3 32b V3 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=qwen3-32b-v3-i1"
    },
    "coreward-qwen3-8b-base-i1": {
      "title": "Coreward Qwen3 8b Base I1 - Q6_K GGUF Model",
      "description": "Download Coreward Qwen3 8b Base I1 in Q6_K quantization format. File size: 6.3 GB. 292 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Coreward Qwen3 8b Base I1, Q6_K, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Coreward Qwen3 8b Base I1",
        "description": "Download Coreward Qwen3 8b Base I1 in Q6_K quantization format. File size: 6.3 GB. 292 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.3 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/CoReward-Qwen3-8B-Base-i1-GGUF/resolve/main/CoReward-Qwen3-8B-Base.i1-Q6_K.gguf",
        "url": "https://huggingface.co/mradermacher/CoReward-Qwen3-8B-Base-i1-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 292
        }
      },
      "openGraph": {
        "title": "Coreward Qwen3 8b Base I1 - GGUF Model Download",
        "description": "Download Coreward Qwen3 8b Base I1 in Q6_K quantization format. File size: 6.3 GB. 292 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=coreward-qwen3-8b-base-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Coreward Qwen3 8b Base I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=coreward-qwen3-8b-base-i1"
    },
    "mistral-local": {
      "title": "Mistral Local - Unknown GGUF Model",
      "description": "Download Mistral Local in Unknown quantization format. Mistral model File size: 9.3 GB. 290 downloads. Direct download from Hugging Face.",
      "keywords": "Mistral Local, Unknown, GGUF model, download, Mistral, Mistral model, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Mistral Local",
        "description": "Download Mistral Local in Unknown quantization format. Mistral model File size: 9.3 GB. 290 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "9.3 GB",
        "downloadUrl": "https://huggingface.co/abhidgp1978/mistral-local/resolve/main/gemma-2b-it.gguf",
        "url": "https://huggingface.co/abhidgp1978/mistral-local",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 290
        }
      },
      "openGraph": {
        "title": "Mistral Local - GGUF Model Download",
        "description": "Download Mistral Local in Unknown quantization format. Mistral model File size: 9.3 GB. 290 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=mistral-local",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Mistral Local GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=mistral-local"
    },
    "mindlink-32b-0801-i1": {
      "title": "Mindlink 32b 0801 I1 - IQ1_S GGUF Model",
      "description": "Download Mindlink 32b 0801 I1 in IQ1_S quantization format. File size: 6.8 GB. 288 downloads. Direct download from Hugging Face.",
      "keywords": "Mindlink 32b 0801 I1, IQ1_S, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Mindlink 32b 0801 I1",
        "description": "Download Mindlink 32b 0801 I1 in IQ1_S quantization format. File size: 6.8 GB. 288 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/MindLink-32B-0801-i1-GGUF/resolve/main/MindLink-32B-0801.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/MindLink-32B-0801-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 288
        }
      },
      "openGraph": {
        "title": "Mindlink 32b 0801 I1 - GGUF Model Download",
        "description": "Download Mindlink 32b 0801 I1 in IQ1_S quantization format. File size: 6.8 GB. 288 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=mindlink-32b-0801-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Mindlink 32b 0801 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=mindlink-32b-0801-i1"
    },
    "dellamix-12b": {
      "title": "Dellamix 12b - Q2_K GGUF Model",
      "description": "Download Dellamix 12b in Q2_K quantization format. File size: 4.5 GB. 284 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Dellamix 12b, Q2_K, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Dellamix 12b",
        "description": "Download Dellamix 12b in Q2_K quantization format. File size: 4.5 GB. 284 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "4.5 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/DellaMix-12B-GGUF/resolve/main/DellaMix-12B.Q2_K.gguf",
        "url": "https://huggingface.co/mradermacher/DellaMix-12B-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 284
        }
      },
      "openGraph": {
        "title": "Dellamix 12b - GGUF Model Download",
        "description": "Download Dellamix 12b in Q2_K quantization format. File size: 4.5 GB. 284 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=dellamix-12b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Dellamix 12b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=dellamix-12b"
    },
    "llada-1-5": {
      "title": "Llada 1.5 - F16 GGUF Model",
      "description": "Download Llada 1.5 in F16 quantization format. File size: 14.9 GB. 283 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Llada 1.5, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Llada 1.5",
        "description": "Download Llada 1.5 in F16 quantization format. File size: 14.9 GB. 283 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "14.9 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/LLaDA-1.5-GGUF/resolve/main/LLaDA-1.5.f16.gguf",
        "url": "https://huggingface.co/mradermacher/LLaDA-1.5-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 283
        }
      },
      "openGraph": {
        "title": "Llada 1.5 - GGUF Model Download",
        "description": "Download Llada 1.5 in F16 quantization format. File size: 14.9 GB. 283 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=llada-1-5",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Llada 1.5 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=llada-1-5"
    },
    "a-x-4-0-abliterated-i1": {
      "title": "A.x 4.0 Abliterated I1 - IQ2_XXS GGUF Model",
      "description": "Download A.x 4.0 Abliterated I1 in IQ2_XXS quantization format. File size: 23.4 GB. 279 downloads. Direct download from Hugging Face.",
      "keywords": "A.x 4.0 Abliterated I1, IQ2_XXS, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "A.x 4.0 Abliterated I1",
        "description": "Download A.x 4.0 Abliterated I1 in IQ2_XXS quantization format. File size: 23.4 GB. 279 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "23.4 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/A.X-4.0-abliterated-i1-GGUF/resolve/main/A.X-4.0-abliterated.i1-IQ2_XXS.gguf",
        "url": "https://huggingface.co/mradermacher/A.X-4.0-abliterated-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 279
        }
      },
      "openGraph": {
        "title": "A.x 4.0 Abliterated I1 - GGUF Model Download",
        "description": "Download A.x 4.0 Abliterated I1 in IQ2_XXS quantization format. File size: 23.4 GB. 279 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=a-x-4-0-abliterated-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "A.x 4.0 Abliterated I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=a-x-4-0-abliterated-i1"
    },
    "coder-p-grpo-7b": {
      "title": "Coder P Grpo 7b - F16 GGUF Model",
      "description": "Download Coder P Grpo 7b in F16 quantization format. File size: 14.2 GB. 278 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Coder P Grpo 7b, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Coder P Grpo 7b",
        "description": "Download Coder P Grpo 7b in F16 quantization format. File size: 14.2 GB. 278 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "14.2 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Coder-P-GRPO-7B-GGUF/resolve/main/Coder-P-GRPO-7B.f16.gguf",
        "url": "https://huggingface.co/mradermacher/Coder-P-GRPO-7B-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 278
        }
      },
      "openGraph": {
        "title": "Coder P Grpo 7b - GGUF Model Download",
        "description": "Download Coder P Grpo 7b in F16 quantization format. File size: 14.2 GB. 278 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=coder-p-grpo-7b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Coder P Grpo 7b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=coder-p-grpo-7b"
    },
    "dans-adventurouswinds-7b-imatrix": {
      "title": "Dans Adventurouswinds 7b Imatrix - IQ1_S GGUF Model",
      "description": "Download Dans Adventurouswinds 7b Imatrix in IQ1_S quantization format. File size: 1.5 GB. 278 downloads. Direct download from Hugging Face.",
      "keywords": "Dans Adventurouswinds 7b Imatrix, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Dans Adventurouswinds 7b Imatrix",
        "description": "Download Dans Adventurouswinds 7b Imatrix in IQ1_S quantization format. File size: 1.5 GB. 278 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.5 GB",
        "downloadUrl": "https://huggingface.co/duyntnet/Dans-AdventurousWinds-7b-imatrix-GGUF/resolve/main/Dans-AdventurousWinds-7b-IQ1_S.gguf",
        "url": "https://huggingface.co/duyntnet/Dans-AdventurousWinds-7b-imatrix-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 278
        }
      },
      "openGraph": {
        "title": "Dans Adventurouswinds 7b Imatrix - GGUF Model Download",
        "description": "Download Dans Adventurouswinds 7b Imatrix in IQ1_S quantization format. File size: 1.5 GB. 278 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=dans-adventurouswinds-7b-imatrix",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Dans Adventurouswinds 7b Imatrix GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=dans-adventurouswinds-7b-imatrix"
    },
    "agentux-4b-i1": {
      "title": "Agentux 4b I1 - IQ1_S GGUF Model",
      "description": "Download Agentux 4b I1 in IQ1_S quantization format. File size: 1.1 GB. 275 downloads. Direct download from Hugging Face.",
      "keywords": "Agentux 4b I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Agentux 4b I1",
        "description": "Download Agentux 4b I1 in IQ1_S quantization format. File size: 1.1 GB. 275 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.1 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/AgentUX-4B-i1-GGUF/resolve/main/AgentUX-4B.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/AgentUX-4B-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 275
        }
      },
      "openGraph": {
        "title": "Agentux 4b I1 - GGUF Model Download",
        "description": "Download Agentux 4b I1 in IQ1_S quantization format. File size: 1.1 GB. 275 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=agentux-4b-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Agentux 4b I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=agentux-4b-i1"
    },
    "mindlink-72b-0801-i1": {
      "title": "Mindlink 72b 0801 I1 - IQ2_XXS GGUF Model",
      "description": "Download Mindlink 72b 0801 I1 in IQ2_XXS quantization format. File size: 23.7 GB. 274 downloads. Direct download from Hugging Face.",
      "keywords": "Mindlink 72b 0801 I1, IQ2_XXS, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Mindlink 72b 0801 I1",
        "description": "Download Mindlink 72b 0801 I1 in IQ2_XXS quantization format. File size: 23.7 GB. 274 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "23.7 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/MindLink-72B-0801-i1-GGUF/resolve/main/MindLink-72B-0801.i1-IQ2_XXS.gguf",
        "url": "https://huggingface.co/mradermacher/MindLink-72B-0801-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 274
        }
      },
      "openGraph": {
        "title": "Mindlink 72b 0801 I1 - GGUF Model Download",
        "description": "Download Mindlink 72b 0801 I1 in IQ2_XXS quantization format. File size: 23.7 GB. 274 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=mindlink-72b-0801-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Mindlink 72b 0801 I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=mindlink-72b-0801-i1"
    },
    "etherealaurora-12b-lorablated": {
      "title": "Etherealaurora 12b Lorablated - Q2_K GGUF Model",
      "description": "Download Etherealaurora 12b Lorablated in Q2_K quantization format. File size: 4.5 GB. 270 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Etherealaurora 12b Lorablated, Q2_K, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Etherealaurora 12b Lorablated",
        "description": "Download Etherealaurora 12b Lorablated in Q2_K quantization format. File size: 4.5 GB. 270 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "4.5 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/EtherealAurora-12B-Lorablated-GGUF/resolve/main/EtherealAurora-12B-Lorablated.Q2_K.gguf",
        "url": "https://huggingface.co/mradermacher/EtherealAurora-12B-Lorablated-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 270
        }
      },
      "openGraph": {
        "title": "Etherealaurora 12b Lorablated - GGUF Model Download",
        "description": "Download Etherealaurora 12b Lorablated in Q2_K quantization format. File size: 4.5 GB. 270 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=etherealaurora-12b-lorablated",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Etherealaurora 12b Lorablated GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=etherealaurora-12b-lorablated"
    },
    "granite-guardian-3-3-8b-i1": {
      "title": "Granite Guardian 3.3 8b I1 - IQ1_S GGUF Model",
      "description": "Download Granite Guardian 3.3 8b I1 in IQ1_S quantization format. File size: 1.7 GB. 270 downloads. Direct download from Hugging Face.",
      "keywords": "Granite Guardian 3.3 8b I1, IQ1_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Granite Guardian 3.3 8b I1",
        "description": "Download Granite Guardian 3.3 8b I1 in IQ1_S quantization format. File size: 1.7 GB. 270 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.7 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/granite-guardian-3.3-8b-i1-GGUF/resolve/main/granite-guardian-3.3-8b.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/granite-guardian-3.3-8b-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 270
        }
      },
      "openGraph": {
        "title": "Granite Guardian 3.3 8b I1 - GGUF Model Download",
        "description": "Download Granite Guardian 3.3 8b I1 in IQ1_S quantization format. File size: 1.7 GB. 270 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=granite-guardian-3-3-8b-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Granite Guardian 3.3 8b I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=granite-guardian-3-3-8b-i1"
    },
    "llama-3-8b-3some-v2-regularized": {
      "title": "Llama 3 8b 3some V2 Regularized - F16 GGUF Model",
      "description": "Download Llama 3 8b 3some V2 Regularized in F16 quantization format. Llama model File size: 15.0 GB. 265 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Llama 3 8b 3some V2 Regularized, F16, GGUF model, download, Llama, Llama model, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Llama 3 8b 3some V2 Regularized",
        "description": "Download Llama 3 8b 3some V2 Regularized in F16 quantization format. Llama model File size: 15.0 GB. 265 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "15.0 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Llama-3-8B-3SOME-v2-Regularized-GGUF/resolve/main/Llama-3-8B-3SOME-v2-Regularized.f16.gguf",
        "url": "https://huggingface.co/mradermacher/Llama-3-8B-3SOME-v2-Regularized-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 265
        }
      },
      "openGraph": {
        "title": "Llama 3 8b 3some V2 Regularized - GGUF Model Download",
        "description": "Download Llama 3 8b 3some V2 Regularized in F16 quantization format. Llama model File size: 15.0 GB. 265 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=llama-3-8b-3some-v2-regularized",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Llama 3 8b 3some V2 Regularized GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=llama-3-8b-3some-v2-regularized"
    },
    "vl-cogito": {
      "title": "Vl Cogito - F16 GGUF Model",
      "description": "Download Vl Cogito in F16 quantization format. File size: 14.2 GB. 264 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Vl Cogito, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Vl Cogito",
        "description": "Download Vl Cogito in F16 quantization format. File size: 14.2 GB. 264 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "14.2 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/VL-Cogito-GGUF/resolve/main/VL-Cogito.f16.gguf",
        "url": "https://huggingface.co/mradermacher/VL-Cogito-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 264
        }
      },
      "openGraph": {
        "title": "Vl Cogito - GGUF Model Download",
        "description": "Download Vl Cogito in F16 quantization format. File size: 14.2 GB. 264 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=vl-cogito",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Vl Cogito GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=vl-cogito"
    },
    "mingle-1-0": {
      "title": "Mingle 1.0 - F16 GGUF Model",
      "description": "Download Mingle 1.0 in F16 quantization format. File size: 14.2 GB. 260 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Mingle 1.0, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Mingle 1.0",
        "description": "Download Mingle 1.0 in F16 quantization format. File size: 14.2 GB. 260 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "14.2 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/MINGLE-1.0-GGUF/resolve/main/MINGLE-1.0.f16.gguf",
        "url": "https://huggingface.co/mradermacher/MINGLE-1.0-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 260
        }
      },
      "openGraph": {
        "title": "Mingle 1.0 - GGUF Model Download",
        "description": "Download Mingle 1.0 in F16 quantization format. File size: 14.2 GB. 260 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=mingle-1-0",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Mingle 1.0 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=mingle-1-0"
    },
    "anthrobomination-70b-ik": {
      "title": "Anthrobomination 70b Ik - Unknown GGUF Model",
      "description": "Download Anthrobomination 70b Ik in Unknown quantization format. File size: 37.2 GB. 251 downloads. Direct download from Hugging Face.",
      "keywords": "Anthrobomination 70b Ik, Unknown, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Anthrobomination 70b Ik",
        "description": "Download Anthrobomination 70b Ik in Unknown quantization format. File size: 37.2 GB. 251 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "37.2 GB",
        "downloadUrl": "https://huggingface.co/Mawdistical/Anthrobomination-70B-IK-GGUF/resolve/main/Mawdistical_Anthrobomination-70B-IQ4_K.gguf",
        "url": "https://huggingface.co/Mawdistical/Anthrobomination-70B-IK-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 251
        }
      },
      "openGraph": {
        "title": "Anthrobomination 70b Ik - GGUF Model Download",
        "description": "Download Anthrobomination 70b Ik in Unknown quantization format. File size: 37.2 GB. 251 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=anthrobomination-70b-ik",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Anthrobomination 70b Ik GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=anthrobomination-70b-ik"
    },
    "buildwelleye-3b-vqa": {
      "title": "Buildwelleye 3b Vqa - F16 GGUF Model",
      "description": "Download Buildwelleye 3b Vqa in F16 quantization format. File size: 5.8 GB. 247 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Buildwelleye 3b Vqa, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Buildwelleye 3b Vqa",
        "description": "Download Buildwelleye 3b Vqa in F16 quantization format. File size: 5.8 GB. 247 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "5.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/BuildwellEYE-3B-VQA-GGUF/resolve/main/BuildwellEYE-3B-VQA.f16.gguf",
        "url": "https://huggingface.co/mradermacher/BuildwellEYE-3B-VQA-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 247
        }
      },
      "openGraph": {
        "title": "Buildwelleye 3b Vqa - GGUF Model Download",
        "description": "Download Buildwelleye 3b Vqa in F16 quantization format. File size: 5.8 GB. 247 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=buildwelleye-3b-vqa",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Buildwelleye 3b Vqa GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=buildwelleye-3b-vqa"
    },
    "geometryreasoning": {
      "title": "Geometryreasoning - F16 GGUF Model",
      "description": "Download Geometryreasoning in F16 quantization format. File size: 5.8 GB. 247 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Geometryreasoning, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Geometryreasoning",
        "description": "Download Geometryreasoning in F16 quantization format. File size: 5.8 GB. 247 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "5.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/GeometryReasoning-GGUF/resolve/main/GeometryReasoning.f16.gguf",
        "url": "https://huggingface.co/mradermacher/GeometryReasoning-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 247
        }
      },
      "openGraph": {
        "title": "Geometryreasoning - GGUF Model Download",
        "description": "Download Geometryreasoning in F16 quantization format. File size: 5.8 GB. 247 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=geometryreasoning",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Geometryreasoning GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=geometryreasoning"
    },
    "minibutler-4b": {
      "title": "Minibutler 4b - F16 GGUF Model",
      "description": "Download Minibutler 4b in F16 quantization format. File size: 7.5 GB. 243 downloads. Direct download from Hugging Face.",
      "keywords": "Minibutler 4b, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Minibutler 4b",
        "description": "Download Minibutler 4b in F16 quantization format. File size: 7.5 GB. 243 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "7.5 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/MiniButler-4B-GGUF/resolve/main/MiniButler-4B.f16.gguf",
        "url": "https://huggingface.co/mradermacher/MiniButler-4B-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 243
        }
      },
      "openGraph": {
        "title": "Minibutler 4b - GGUF Model Download",
        "description": "Download Minibutler 4b in F16 quantization format. File size: 7.5 GB. 243 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=minibutler-4b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Minibutler 4b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=minibutler-4b"
    },
    "neta-lumina": {
      "title": "Neta Lumina - BF16 GGUF Model",
      "description": "Download Neta Lumina in BF16 quantization format. File size: 5.4 GB. 242 downloads. Direct download from Hugging Face.",
      "keywords": "Neta Lumina, BF16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Neta Lumina",
        "description": "Download Neta Lumina in BF16 quantization format. File size: 5.4 GB. 242 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "5.4 GB",
        "downloadUrl": "https://huggingface.co/neta-art/neta-lumina-gguf/resolve/main/checkpoint-e3_s9658-BF16.gguf",
        "url": "https://huggingface.co/neta-art/neta-lumina-gguf",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 242
        }
      },
      "openGraph": {
        "title": "Neta Lumina - GGUF Model Download",
        "description": "Download Neta Lumina in BF16 quantization format. File size: 5.4 GB. 242 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=neta-lumina",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Neta Lumina GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=neta-lumina"
    },
    "agentux-4b": {
      "title": "Agentux 4b - F16 GGUF Model",
      "description": "Download Agentux 4b in F16 quantization format. File size: 8.2 GB. 238 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Agentux 4b, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Agentux 4b",
        "description": "Download Agentux 4b in F16 quantization format. File size: 8.2 GB. 238 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "8.2 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/AgentUX-4B-GGUF/resolve/main/AgentUX-4B.f16.gguf",
        "url": "https://huggingface.co/mradermacher/AgentUX-4B-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 238
        }
      },
      "openGraph": {
        "title": "Agentux 4b - GGUF Model Download",
        "description": "Download Agentux 4b in F16 quantization format. File size: 8.2 GB. 238 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=agentux-4b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Agentux 4b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=agentux-4b"
    },
    "rawmaw-70b": {
      "title": "Rawmaw 70b - Q5_K_S GGUF Model",
      "description": "Download Rawmaw 70b in Q5_K_S quantization format. File size: 3.4 GB. 224 downloads. Direct download from Hugging Face.",
      "keywords": "Rawmaw 70b, Q5_K_S, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Rawmaw 70b",
        "description": "Download Rawmaw 70b in Q5_K_S quantization format. File size: 3.4 GB. 224 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "3.4 GB",
        "downloadUrl": "https://huggingface.co/Mawdistical/RAWMAW-70B-GGUF/resolve/main/Mawdistical_RAWMAW-70B-Q5_K_S-00002-of-00002.gguf",
        "url": "https://huggingface.co/Mawdistical/RAWMAW-70B-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 224
        }
      },
      "openGraph": {
        "title": "Rawmaw 70b - GGUF Model Download",
        "description": "Download Rawmaw 70b in Q5_K_S quantization format. File size: 3.4 GB. 224 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=rawmaw-70b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Rawmaw 70b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=rawmaw-70b"
    },
    "pd-gemma-3n-e4b-v2": {
      "title": "Pd Gemma 3n E4b V2 - F16 GGUF Model",
      "description": "Download Pd Gemma 3n E4b V2 in F16 quantization format. File size: 12.8 GB. 223 downloads. Direct download from Hugging Face.",
      "keywords": "Pd Gemma 3n E4b V2, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Pd Gemma 3n E4b V2",
        "description": "Download Pd Gemma 3n E4b V2 in F16 quantization format. File size: 12.8 GB. 223 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "12.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/PD_gemma-3n-E4B-v2-GGUF/resolve/main/PD_gemma-3n-E4B-v2.f16.gguf",
        "url": "https://huggingface.co/mradermacher/PD_gemma-3n-E4B-v2-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 223
        }
      },
      "openGraph": {
        "title": "Pd Gemma 3n E4b V2 - GGUF Model Download",
        "description": "Download Pd Gemma 3n E4b V2 in F16 quantization format. File size: 12.8 GB. 223 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=pd-gemma-3n-e4b-v2",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Pd Gemma 3n E4b V2 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=pd-gemma-3n-e4b-v2"
    },
    "cthulhu-24b-v1-1": {
      "title": "Cthulhu 24b V1.1 - Unknown GGUF Model",
      "description": "Download Cthulhu 24b V1.1 in Unknown quantization format. File size: 9.9 GB. 221 downloads. Direct download from Hugging Face.",
      "keywords": "Cthulhu 24b V1.1, Unknown, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Cthulhu 24b V1.1",
        "description": "Download Cthulhu 24b V1.1 in Unknown quantization format. File size: 9.9 GB. 221 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "9.9 GB",
        "downloadUrl": "https://huggingface.co/Fentible/Cthulhu-24B-v1.1-GGUF/resolve/main/Cthulhu-24B-v1.1-IQ3_M.gguf",
        "url": "https://huggingface.co/Fentible/Cthulhu-24B-v1.1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 221
        }
      },
      "openGraph": {
        "title": "Cthulhu 24b V1.1 - GGUF Model Download",
        "description": "Download Cthulhu 24b V1.1 in Unknown quantization format. File size: 9.9 GB. 221 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=cthulhu-24b-v1-1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Cthulhu 24b V1.1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=cthulhu-24b-v1-1"
    },
    "deprecated-qwen-image-test": {
      "title": "Deprecated Qwen Image Test - Q4_K_M GGUF Model",
      "description": "Download Deprecated Qwen Image Test in Q4_K_M quantization format. Qwen model File size: 10.7 GB. 219 downloads. 9 likes. Direct download from Hugging Face.",
      "keywords": "Deprecated Qwen Image Test, Q4_K_M, GGUF model, download, Qwen, Qwen model, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Deprecated Qwen Image Test",
        "description": "Download Deprecated Qwen Image Test in Q4_K_M quantization format. Qwen model File size: 10.7 GB. 219 downloads. 9 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "10.7 GB",
        "downloadUrl": "https://huggingface.co/lym00/DEPRECATED-qwen-image-gguf-test/resolve/main/qwen_image-Q4_K_M.gguf",
        "url": "https://huggingface.co/lym00/DEPRECATED-qwen-image-gguf-test",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 9
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 219
        }
      },
      "openGraph": {
        "title": "Deprecated Qwen Image Test - GGUF Model Download",
        "description": "Download Deprecated Qwen Image Test in Q4_K_M quantization format. Qwen model File size: 10.7 GB. 219 downloads. 9 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=deprecated-qwen-image-test",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Deprecated Qwen Image Test GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=deprecated-qwen-image-test"
    },
    "cogito-v1-custom-qwen-32b-i1": {
      "title": "Cogito V1 Custom Qwen 32b I1 - IQ1_S GGUF Model",
      "description": "Download Cogito V1 Custom Qwen 32b I1 in IQ1_S quantization format. Qwen model File size: 6.8 GB. 218 downloads. Direct download from Hugging Face.",
      "keywords": "Cogito V1 Custom Qwen 32b I1, IQ1_S, GGUF model, download, Qwen, Qwen model, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Cogito V1 Custom Qwen 32b I1",
        "description": "Download Cogito V1 Custom Qwen 32b I1 in IQ1_S quantization format. Qwen model File size: 6.8 GB. 218 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/cogito-v1-custom-qwen-32B-i1-GGUF/resolve/main/cogito-v1-custom-qwen-32B.i1-IQ1_S.gguf",
        "url": "https://huggingface.co/mradermacher/cogito-v1-custom-qwen-32B-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 218
        }
      },
      "openGraph": {
        "title": "Cogito V1 Custom Qwen 32b I1 - GGUF Model Download",
        "description": "Download Cogito V1 Custom Qwen 32b I1 in IQ1_S quantization format. Qwen model File size: 6.8 GB. 218 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=cogito-v1-custom-qwen-32b-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Cogito V1 Custom Qwen 32b I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=cogito-v1-custom-qwen-32b-i1"
    },
    "inclusionai-ling-lite-1-5-2506": {
      "title": "Inclusionai.ling Lite 1.5 2506 - F16 GGUF Model",
      "description": "Download Inclusionai.ling Lite 1.5 2506 in F16 quantization format. File size: 31.3 GB. 216 downloads. Direct download from Hugging Face.",
      "keywords": "Inclusionai.ling Lite 1.5 2506, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Inclusionai.ling Lite 1.5 2506",
        "description": "Download Inclusionai.ling Lite 1.5 2506 in F16 quantization format. File size: 31.3 GB. 216 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "31.3 GB",
        "downloadUrl": "https://huggingface.co/DevQuasar/inclusionAI.Ling-lite-1.5-2506-GGUF/resolve/main/inclusionAI.Ling-lite-1.5-2506.f16.gguf",
        "url": "https://huggingface.co/DevQuasar/inclusionAI.Ling-lite-1.5-2506-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 216
        }
      },
      "openGraph": {
        "title": "Inclusionai.ling Lite 1.5 2506 - GGUF Model Download",
        "description": "Download Inclusionai.ling Lite 1.5 2506 in F16 quantization format. File size: 31.3 GB. 216 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=inclusionai-ling-lite-1-5-2506",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Inclusionai.ling Lite 1.5 2506 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=inclusionai-ling-lite-1-5-2506"
    },
    "uigen-t3-4b-preview": {
      "title": "Uigen T3 4b Preview - BF16 GGUF Model",
      "description": "Download Uigen T3 4b Preview in BF16 quantization format. File size: 7.5 GB. 209 downloads. Direct download from Hugging Face.",
      "keywords": "Uigen T3 4b Preview, BF16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Uigen T3 4b Preview",
        "description": "Download Uigen T3 4b Preview in BF16 quantization format. File size: 7.5 GB. 209 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "7.5 GB",
        "downloadUrl": "https://huggingface.co/prithivMLmods/UIGEN-T3-4B-Preview-GGUF/resolve/main/ UIGEN-T3-4B-Preview.BF16.gguf",
        "url": "https://huggingface.co/prithivMLmods/UIGEN-T3-4B-Preview-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 209
        }
      },
      "openGraph": {
        "title": "Uigen T3 4b Preview - GGUF Model Download",
        "description": "Download Uigen T3 4b Preview in BF16 quantization format. File size: 7.5 GB. 209 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=uigen-t3-4b-preview",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Uigen T3 4b Preview GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=uigen-t3-4b-preview"
    },
    "ii-search-4b": {
      "title": "Ii Search 4b - F16 GGUF Model",
      "description": "Download Ii Search 4b in F16 quantization format. File size: 8.2 GB. 205 downloads. Direct download from Hugging Face.",
      "keywords": "Ii Search 4b, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Ii Search 4b",
        "description": "Download Ii Search 4b in F16 quantization format. File size: 8.2 GB. 205 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "8.2 GB",
        "downloadUrl": "https://huggingface.co/gabriellarson/II-Search-4B-GGUF/resolve/main/II-Search-4B-F16.gguf",
        "url": "https://huggingface.co/gabriellarson/II-Search-4B-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 205
        }
      },
      "openGraph": {
        "title": "Ii Search 4b - GGUF Model Download",
        "description": "Download Ii Search 4b in F16 quantization format. File size: 8.2 GB. 205 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=ii-search-4b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Ii Search 4b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=ii-search-4b"
    },
    "majority-voting-qwen3-4b-base-i1": {
      "title": "Majority Voting Qwen3 4b Base I1 - Q6_K GGUF Model",
      "description": "Download Majority Voting Qwen3 4b Base I1 in Q6_K quantization format. File size: 3.4 GB. 205 downloads. Direct download from Hugging Face.",
      "keywords": "Majority Voting Qwen3 4b Base I1, Q6_K, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Majority Voting Qwen3 4b Base I1",
        "description": "Download Majority Voting Qwen3 4b Base I1 in Q6_K quantization format. File size: 3.4 GB. 205 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "3.4 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Majority-Voting-Qwen3-4B-Base-i1-GGUF/resolve/main/Majority-Voting-Qwen3-4B-Base.i1-Q6_K.gguf",
        "url": "https://huggingface.co/mradermacher/Majority-Voting-Qwen3-4B-Base-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 205
        }
      },
      "openGraph": {
        "title": "Majority Voting Qwen3 4b Base I1 - GGUF Model Download",
        "description": "Download Majority Voting Qwen3 4b Base I1 in Q6_K quantization format. File size: 3.4 GB. 205 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=majority-voting-qwen3-4b-base-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Majority Voting Qwen3 4b Base I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=majority-voting-qwen3-4b-base-i1"
    },
    "coreward-qwen3-4b-base-i1": {
      "title": "Coreward Qwen3 4b Base I1 - Q6_K GGUF Model",
      "description": "Download Coreward Qwen3 4b Base I1 in Q6_K quantization format. File size: 3.4 GB. 202 downloads. Direct download from Hugging Face.",
      "keywords": "Coreward Qwen3 4b Base I1, Q6_K, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Coreward Qwen3 4b Base I1",
        "description": "Download Coreward Qwen3 4b Base I1 in Q6_K quantization format. File size: 3.4 GB. 202 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "3.4 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/CoReward-Qwen3-4B-Base-i1-GGUF/resolve/main/CoReward-Qwen3-4B-Base.i1-Q6_K.gguf",
        "url": "https://huggingface.co/mradermacher/CoReward-Qwen3-4B-Base-i1-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 202
        }
      },
      "openGraph": {
        "title": "Coreward Qwen3 4b Base I1 - GGUF Model Download",
        "description": "Download Coreward Qwen3 4b Base I1 in Q6_K quantization format. File size: 3.4 GB. 202 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=coreward-qwen3-4b-base-i1",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Coreward Qwen3 4b Base I1 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=coreward-qwen3-4b-base-i1"
    },
    "qwen3-reranker-0-6b-seq-cls": {
      "title": "Qwen3 Reranker 0.6b Seq Cls - BF16 GGUF Model",
      "description": "Download Qwen3 Reranker 0.6b Seq Cls in BF16 quantization format. File size: 1.1 GB. 202 downloads. Direct download from Hugging Face.",
      "keywords": "Qwen3 Reranker 0.6b Seq Cls, BF16, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Qwen3 Reranker 0.6b Seq Cls",
        "description": "Download Qwen3 Reranker 0.6b Seq Cls in BF16 quantization format. File size: 1.1 GB. 202 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "1.1 GB",
        "downloadUrl": "https://huggingface.co/prithivMLmods/Qwen3-Reranker-0.6B-seq-cls-GGUF/resolve/main/Qwen3-Reranker-0.6B-seq-cls.BF16.gguf",
        "url": "https://huggingface.co/prithivMLmods/Qwen3-Reranker-0.6B-seq-cls-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 202
        }
      },
      "openGraph": {
        "title": "Qwen3 Reranker 0.6b Seq Cls - GGUF Model Download",
        "description": "Download Qwen3 Reranker 0.6b Seq Cls in BF16 quantization format. File size: 1.1 GB. 202 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=qwen3-reranker-0-6b-seq-cls",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Qwen3 Reranker 0.6b Seq Cls GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=qwen3-reranker-0-6b-seq-cls"
    },
    "gemma-3n-4b-vision-finetuned": {
      "title": "Gemma 3n 4b Vision Finetuned - F16 GGUF Model",
      "description": "Download Gemma 3n 4b Vision Finetuned in F16 quantization format. Gemma model File size: 12.8 GB. 194 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Gemma 3n 4b Vision Finetuned, F16, GGUF model, download, Gemma, Gemma model, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Gemma 3n 4b Vision Finetuned",
        "description": "Download Gemma 3n 4b Vision Finetuned in F16 quantization format. Gemma model File size: 12.8 GB. 194 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "12.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Gemma-3n-4b-Vision-Finetuned-GGUF/resolve/main/Gemma-3n-4b-Vision-Finetuned.f16.gguf",
        "url": "https://huggingface.co/mradermacher/Gemma-3n-4b-Vision-Finetuned-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 194
        }
      },
      "openGraph": {
        "title": "Gemma 3n 4b Vision Finetuned - GGUF Model Download",
        "description": "Download Gemma 3n 4b Vision Finetuned in F16 quantization format. Gemma model File size: 12.8 GB. 194 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=gemma-3n-4b-vision-finetuned",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Gemma 3n 4b Vision Finetuned GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=gemma-3n-4b-vision-finetuned"
    },
    "camel-doc-ocr-080125": {
      "title": "Camel Doc Ocr 080125 - F16 GGUF Model",
      "description": "Download Camel Doc Ocr 080125 in F16 quantization format. File size: 14.2 GB. 194 downloads. Direct download from Hugging Face.",
      "keywords": "Camel Doc Ocr 080125, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Camel Doc Ocr 080125",
        "description": "Download Camel Doc Ocr 080125 in F16 quantization format. File size: 14.2 GB. 194 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "14.2 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Camel-Doc-OCR-080125-GGUF/resolve/main/Camel-Doc-OCR-080125.f16.gguf",
        "url": "https://huggingface.co/mradermacher/Camel-Doc-OCR-080125-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 194
        }
      },
      "openGraph": {
        "title": "Camel Doc Ocr 080125 - GGUF Model Download",
        "description": "Download Camel Doc Ocr 080125 in F16 quantization format. File size: 14.2 GB. 194 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=camel-doc-ocr-080125",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Camel Doc Ocr 080125 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=camel-doc-ocr-080125"
    },
    "latitudegames-muse-12b": {
      "title": "Latitudegames Muse 12b - Q2_K GGUF Model",
      "description": "Download Latitudegames Muse 12b in Q2_K quantization format. File size: 4.5 GB. 193 downloads. Direct download from Hugging Face.",
      "keywords": "Latitudegames Muse 12b, Q2_K, GGUF model, download, medium model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Latitudegames Muse 12b",
        "description": "Download Latitudegames Muse 12b in Q2_K quantization format. File size: 4.5 GB. 193 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "4.5 GB",
        "downloadUrl": "https://huggingface.co/tensorblock/LatitudeGames_Muse-12B-GGUF/resolve/main/Muse-12B-Q2_K.gguf",
        "url": "https://huggingface.co/tensorblock/LatitudeGames_Muse-12B-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 193
        }
      },
      "openGraph": {
        "title": "Latitudegames Muse 12b - GGUF Model Download",
        "description": "Download Latitudegames Muse 12b in Q2_K quantization format. File size: 4.5 GB. 193 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=latitudegames-muse-12b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Latitudegames Muse 12b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=latitudegames-muse-12b"
    },
    "aquif-3-moe-17b-a2-8b": {
      "title": "Aquif 3 Moe 17b A2.8b - Q2_K GGUF Model",
      "description": "Download Aquif 3 Moe 17b A2.8b in Q2_K quantization format. File size: 6.4 GB. 192 downloads. Direct download from Hugging Face.",
      "keywords": "Aquif 3 Moe 17b A2.8b, Q2_K, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Aquif 3 Moe 17b A2.8b",
        "description": "Download Aquif 3 Moe 17b A2.8b in Q2_K quantization format. File size: 6.4 GB. 192 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.4 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/aquif-3-moe-17b-a2.8b-GGUF/resolve/main/aquif-3-moe-17b-a2.8b.Q2_K.gguf",
        "url": "https://huggingface.co/mradermacher/aquif-3-moe-17b-a2.8b-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 192
        }
      },
      "openGraph": {
        "title": "Aquif 3 Moe 17b A2.8b - GGUF Model Download",
        "description": "Download Aquif 3 Moe 17b A2.8b in Q2_K quantization format. File size: 6.4 GB. 192 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=aquif-3-moe-17b-a2-8b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Aquif 3 Moe 17b A2.8b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=aquif-3-moe-17b-a2-8b"
    },
    "mmada-8b-mixcot": {
      "title": "Mmada 8b Mixcot - F16 GGUF Model",
      "description": "Download Mmada 8b Mixcot in F16 quantization format. File size: 15.1 GB. 191 downloads. Direct download from Hugging Face.",
      "keywords": "Mmada 8b Mixcot, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Mmada 8b Mixcot",
        "description": "Download Mmada 8b Mixcot in F16 quantization format. File size: 15.1 GB. 191 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "15.1 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/MMaDA-8B-MixCoT-GGUF/resolve/main/MMaDA-8B-MixCoT.f16.gguf",
        "url": "https://huggingface.co/mradermacher/MMaDA-8B-MixCoT-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 191
        }
      },
      "openGraph": {
        "title": "Mmada 8b Mixcot - GGUF Model Download",
        "description": "Download Mmada 8b Mixcot in F16 quantization format. File size: 15.1 GB. 191 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=mmada-8b-mixcot",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Mmada 8b Mixcot GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=mmada-8b-mixcot"
    },
    "gemma3n-e4b-ap": {
      "title": "Gemma3n E4b Ap - F16 GGUF Model",
      "description": "Download Gemma3n E4b Ap in F16 quantization format. File size: 12.8 GB. 189 downloads. Direct download from Hugging Face.",
      "keywords": "Gemma3n E4b Ap, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Gemma3n E4b Ap",
        "description": "Download Gemma3n E4b Ap in F16 quantization format. File size: 12.8 GB. 189 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "12.8 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Gemma3n-E4B-ap-GGUF/resolve/main/Gemma3n-E4B-ap.f16.gguf",
        "url": "https://huggingface.co/mradermacher/Gemma3n-E4B-ap-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 189
        }
      },
      "openGraph": {
        "title": "Gemma3n E4b Ap - GGUF Model Download",
        "description": "Download Gemma3n E4b Ap in F16 quantization format. File size: 12.8 GB. 189 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=gemma3n-e4b-ap",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Gemma3n E4b Ap GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=gemma3n-e4b-ap"
    },
    "llama-3-2-3b-it-grpo-250404": {
      "title": "Llama 3.2 3b It Grpo 250404 - BF16 GGUF Model",
      "description": "Download Llama 3.2 3b It Grpo 250404 in BF16 quantization format. Llama model File size: 6.0 GB. 183 downloads. Direct download from Hugging Face.",
      "keywords": "Llama 3.2 3b It Grpo 250404, BF16, GGUF model, download, Llama, Llama model, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Llama 3.2 3b It Grpo 250404",
        "description": "Download Llama 3.2 3b It Grpo 250404 in BF16 quantization format. Llama model File size: 6.0 GB. 183 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "6.0 GB",
        "downloadUrl": "https://huggingface.co/prithivMLmods/llama-3.2-3b-it-grpo-250404-GGUF/resolve/main/ llama-3.2-3b-it-grpo-250404.BF16.gguf",
        "url": "https://huggingface.co/prithivMLmods/llama-3.2-3b-it-grpo-250404-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 183
        }
      },
      "openGraph": {
        "title": "Llama 3.2 3b It Grpo 250404 - GGUF Model Download",
        "description": "Download Llama 3.2 3b It Grpo 250404 in BF16 quantization format. Llama model File size: 6.0 GB. 183 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=llama-3-2-3b-it-grpo-250404",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Llama 3.2 3b It Grpo 250404 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=llama-3-2-3b-it-grpo-250404"
    },
    "hydramind": {
      "title": "Hydramind - Q2_K GGUF Model",
      "description": "Download Hydramind in Q2_K quantization format. File size: 10.5 GB. 176 downloads. Direct download from Hugging Face.",
      "keywords": "Hydramind, Q2_K, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Hydramind",
        "description": "Download Hydramind in Q2_K quantization format. File size: 10.5 GB. 176 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "10.5 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/HydraMind-GGUF/resolve/main/HydraMind.Q2_K.gguf",
        "url": "https://huggingface.co/mradermacher/HydraMind-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 176
        }
      },
      "openGraph": {
        "title": "Hydramind - GGUF Model Download",
        "description": "Download Hydramind in Q2_K quantization format. File size: 10.5 GB. 176 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=hydramind",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Hydramind GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=hydramind"
    },
    "graph-r1-7b": {
      "title": "Graph R1 7b - F16 GGUF Model",
      "description": "Download Graph R1 7b in F16 quantization format. File size: 14.2 GB. 175 downloads. 1 likes. Direct download from Hugging Face.",
      "keywords": "Graph R1 7b, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Graph R1 7b",
        "description": "Download Graph R1 7b in F16 quantization format. File size: 14.2 GB. 175 downloads. 1 likes. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "14.2 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/Graph-R1-7B-GGUF/resolve/main/Graph-R1-7B.f16.gguf",
        "url": "https://huggingface.co/mradermacher/Graph-R1-7B-GGUF",
        "aggregateRating": {
          "@type": "AggregateRating",
          "ratingValue": 1,
          "ratingCount": 1
        },
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 175
        }
      },
      "openGraph": {
        "title": "Graph R1 7b - GGUF Model Download",
        "description": "Download Graph R1 7b in F16 quantization format. File size: 14.2 GB. 175 downloads. 1 likes. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=graph-r1-7b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Graph R1 7b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=graph-r1-7b"
    },
    "arc-teacher-8b": {
      "title": "Arc Teacher 8b - F16 GGUF Model",
      "description": "Download Arc Teacher 8b in F16 quantization format. File size: 15.3 GB. 173 downloads. Direct download from Hugging Face.",
      "keywords": "Arc Teacher 8b, F16, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Arc Teacher 8b",
        "description": "Download Arc Teacher 8b in F16 quantization format. File size: 15.3 GB. 173 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "15.3 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/arc-teacher-8b-GGUF/resolve/main/arc-teacher-8b.f16.gguf",
        "url": "https://huggingface.co/mradermacher/arc-teacher-8b-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 173
        }
      },
      "openGraph": {
        "title": "Arc Teacher 8b - GGUF Model Download",
        "description": "Download Arc Teacher 8b in F16 quantization format. File size: 15.3 GB. 173 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=arc-teacher-8b",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Arc Teacher 8b GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=arc-teacher-8b"
    },
    "qwen3-32b-v3": {
      "title": "Qwen3 32b V3 - Q2_K GGUF Model",
      "description": "Download Qwen3 32b V3 in Q2_K quantization format. File size: 11.5 GB. 171 downloads. Direct download from Hugging Face.",
      "keywords": "Qwen3 32b V3, Q2_K, GGUF model, download, large model",
      "structuredData": {
        "@context": "https://schema.org",
        "@type": "SoftwareApplication",
        "name": "Qwen3 32b V3",
        "description": "Download Qwen3 32b V3 in Q2_K quantization format. File size: 11.5 GB. 171 downloads. Direct download from Hugging Face.",
        "applicationCategory": "Machine Learning Model",
        "operatingSystem": "Cross-platform",
        "fileFormat": "GGUF",
        "fileSize": "11.5 GB",
        "downloadUrl": "https://huggingface.co/mradermacher/qwen3-32b-v3-GGUF/resolve/main/qwen3-32b-v3.Q2_K.gguf",
        "url": "https://huggingface.co/mradermacher/qwen3-32b-v3-GGUF",
        "interactionStatistic": {
          "@type": "InteractionCounter",
          "interactionType": "https://schema.org/DownloadAction",
          "userInteractionCount": 171
        }
      },
      "openGraph": {
        "title": "Qwen3 32b V3 - GGUF Model Download",
        "description": "Download Qwen3 32b V3 in Q2_K quantization format. File size: 11.5 GB. 171 downloads. Direct download from Hugging Face.",
        "type": "website",
        "url": "https://local-ai-zone.github.io/#model=qwen3-32b-v3",
        "image": "https://local-ai-zone.github.io/og-image-model.png",
        "image:alt": "Qwen3 32b V3 GGUF model preview",
        "image:width": "1200",
        "image:height": "630"
      },
      "canonical": "https://local-ai-zone.github.io/#model=qwen3-32b-v3"
    }
  }
}